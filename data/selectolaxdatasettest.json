[
    {
        "conversations": [
            {
                "from": "human",
                "value": "Please learn from the content of this file."
            },
            {
                "from": "observation",
                "value": "# coding:utf-8\n\"\"\"A simple benchmark that measures speed of lxml and selectolax.\n\nHow the benchmark works\n-----------------------\n\nFor each page, we extract:\n\n1) Title\n2) Number of script tag\n3) The ``href`` attribute from all links\n4) The content of the Meta description tag\n\n\"\"\"\nimport functools\nimport json\nimport time\n\nfrom bs4 import BeautifulSoup\nfrom html5_parser import parse\nfrom lxml.html import fromstring\nfrom selectolax.parser import HTMLParser\n\nfrom selectolax.lexbor import LexborHTMLParser\n\nbad_urls = []\n\n\ndef bs4_parser(html_content, parser=HTMLParser):\n    soup = BeautifulSoup(html_content, 'html.parser')\n    title_text = soup.title.string\n    assert title_text\n\n    a_hrefs = [a.attrs.get('href', '') for a in soup.find_all('a')]\n    assert len(a_hrefs) >= 5, 'href'\n\n    num_script_tags = len(soup.find_all('script'))\n    assert num_script_tags > 0, 'script'\n    meta_description = soup.find('meta', attrs={\"name\": \"description\"})\n    if meta_description:\n        meta_content = meta_description.get('content')\n\n\ndef selectolax_parser(html_content, parser=HTMLParser):\n    tree = parser(html_content)\n    title_text = \"\"\n    title_node = tree.css_first('title')\n    if title_node:\n        title_text = title_node.text()\n    assert title_text\n\n    a_hrefs = [a.attrs.get('href', '') for a in tree.css('a[href]')]\n    assert len(a_hrefs) >= 5, 'href'\n\n    num_script_tags = len(tree.css('script'))\n    assert num_script_tags > 0, 'script'\n    meta_description = tree.css_first('meta[name=\"description\"]')\n    if meta_description:\n        meta_content = meta_description.attrs.sget('content', '')\n\n\ndef lxml_parser(html_content):\n    tree = fromstring(html_content)\n    title_text = tree.xpath('//title/text()')\n    assert title_text, 'title'\n\n    a_hrefs = [a.attrib.get('href', '') for a in tree.xpath('//a[@href]')]\n    assert len(a_hrefs) >= 5, 'href'\n\n    num_script_tags = len(tree.xpath('//script'))\n    assert num_script_tags > 0, 'script'\n    meta_description = tree.xpath('meta[@name=\"description\"]')\n    if meta_description:\n        meta_content = meta_description[0].attrib.get('content', '')\n\n\ndef html5_parser(html_content):\n    tree = parse(html_content)\n    title_text = tree.xpath('//title/text()')\n    assert title_text, 'title'\n\n    a_hrefs = [a.attrib.get('href', '') for a in tree.xpath('//a[@href]')]\n    assert len(a_hrefs) >= 5, 'href'\n\n    num_script_tags = len(tree.xpath('//script'))\n    assert num_script_tags > 0, 'script'\n    meta_description = tree.xpath('meta[@name=\"description\"]')\n    if meta_description:\n        meta_content = meta_description[0].attrib.get('content', '')\n\n\ndef _perform_test(pages, parse_func):\n    for page in pages:\n        parse_func(page['html'])\n\n\ndef main():\n    #\n    # This file contains 754 main pages from the top internet domains (according to Alexa rank).\n    # That translates to 324MB of HTML data.\n    # Because of potential copyright infringements, I don't publish it.\n    #\n    html_pages = [json.loads(page) for page in open('pages/pages.json', 'rt')]\n    available_parsers = [\n        ('bs4', bs4_parser,),\n        ('lxml', lxml_parser,),\n        ('html5_parser', html5_parser,),\n        ('modest', selectolax_parser,),\n        ('lexbor', functools.partial(selectolax_parser, parser=LexborHTMLParser)),\n    ]\n    for parser_name, parser in available_parsers:\n        start = time.time()\n        _perform_test(html_pages, parser)\n        print('%r: %s' % (parser_name, time.time() - start))\n\n\nif __name__ == '__main__':\n    main()\n"
            }
        ]
    },
    {
        "conversations": [
            {
                "from": "human",
                "value": "Please learn from the content of this file."
            },
            {
                "from": "observation",
                "value": "import calendar\nimport json\nimport os\nimport sys\nimport textwrap\nimport datetime\nfrom email.utils import formatdate, parsedate\nfrom urllib.parse import urlparse\n\nimport appdirs\nimport click\nimport github3\nimport pipdate\nimport requests\nfrom urllib3.util.retry import Retry\nfrom cachecontrol.caches import FileCache\nfrom cachecontrol.heuristics import BaseHeuristic\nfrom cachecontrol import CacheControl, CacheControlAdapter\nfrom halo import Halo\nfrom selectolax.parser import HTMLParser\nfrom tabulate import tabulate\n\nfrom ghtopdep import __version__\n\nPACKAGE_NAME = \"ghtopdep\"\nCACHE_DIR = appdirs.user_cache_dir(PACKAGE_NAME)\nNEXT_BUTTON_SELECTOR = \"#dependents > div.paginate-container > div > a\"\nITEM_SELECTOR = \"#dependents > div.Box > div.flex-items-center\"\nREPO_SELECTOR = \"span > a.text-bold\"\nSTARS_SELECTOR = \"div > span:nth-child(1)\"\nGITHUB_URL = \"https://github.com\"\n\nif pipdate.needs_checking(PACKAGE_NAME):\n    msg = pipdate.check(PACKAGE_NAME, __version__.__version__)\n    click.echo(msg)\n\n\nclass OneDayHeuristic(BaseHeuristic):\n    cacheable_by_default_statuses = {\n        200, 203, 204, 206, 300, 301, 404, 405, 410, 414, 501\n    }\n\n    def update_headers(self, response):\n        if response.status not in self.cacheable_by_default_statuses:\n            return {}\n\n        date = parsedate(response.headers[\"date\"])\n        expires = datetime.datetime(*date[:6]) + datetime.timedelta(days=1)\n        return {\"expires\": formatdate(calendar.timegm(expires.timetuple())), \"cache-control\": \"public\"}\n\n    def warning(self, response):\n        msg = \"Automatically cached! Response is Stale.\"\n        return \"110 - {0}\".format(msg)\n\n\ndef already_added(repo_url, repos):\n    for repo in repos:\n        if repo['url'] == repo_url:\n            return True\n\n\ndef fetch_description(gh, relative_url):\n    _, owner, repository = relative_url.split(\"/\")\n    repository = gh.repository(owner, repository)\n    repo_description = \" \"\n    if repository.description:\n        repo_description = textwrap.shorten(repository.description, width=60, placeholder=\"...\")\n    return repo_description\n\n\ndef sort_repos(repos, rows):\n    sorted_repos = sorted(repos, key=lambda i: i[\"stars\"], reverse=True)\n    return sorted_repos[:rows]\n\n\ndef humanize(num):\n    if num < 1_000:\n        return num\n    elif num < 10_000:\n        return \"{}K\".format(round(num / 100) / 10)\n    elif num < 1_000_000:\n        return \"{}K\".format(round(num / 1_000))\n    else:\n        return num\n\n\ndef readable_stars(repos):\n    for repo in repos:\n        repo[\"stars\"] = humanize(repo[\"stars\"])\n    return repos\n\n\ndef show_result(repos, total_repos_count, more_than_zero_count, destinations, table):\n    if table:\n        if repos:\n            repos = readable_stars(repos)\n            click.echo(tabulate(repos, headers=\"keys\", tablefmt=\"github\"))\n            click.echo(\"found {0} {1} others {2} are private\".format(total_repos_count, destinations, destinations))\n            click.echo(\"found {0} {1} with more than zero star\".format(more_than_zero_count, destinations))\n        else:\n            click.echo(\"Doesn't find any {0} that match search request\".format(destinations))\n    else:\n        click.echo(json.dumps(repos))\n\n\ndef get_page_url(sess, url, destination):\n    page_url = \"{0}/network/dependents?dependent_type={1}\".format(url, destination.upper())\n    main_response = sess.get(page_url)\n    parsed_node = HTMLParser(main_response.text)\n    link = parsed_node.css('.select-menu-item')\n    if link:\n        packages = []\n        for i in link:\n            repo_url = \"https://github.com/{}\".format(i.attributes['href'])\n            res = requests.get(repo_url)\n            parsed_item = HTMLParser(res.text)\n            package_id = urlparse(i.attributes[\"href\"]).query.split(\"=\")[1]\n            selector = '.table-list-filters a:first-child'\n            count = parsed_item.css(selector)[0].text().split()[0].replace(\",\", \"\")\n            packages.append({\"count\": int(count), \"package_id\": package_id})\n        sorted_packages = sorted(packages, key=lambda k: k['count'], reverse=True)\n        most_popular_package_id = sorted_packages[0].get(\"package_id\")\n        page_url = \"{0}/network/dependents?dependent_type={1}&package_id={2}\".format(url, destination.upper(),\n                                                                                     most_popular_package_id)\n    return page_url\n\n\n@click.command()\n@click.argument(\"url\")\n@click.option(\"--repositories/--packages\", default=True, help=\"Sort repositories or packages (default repositories)\")\n@click.option(\"--table/--json\", default=True, help=\"View mode\")\n@click.option(\"--report\", is_flag=True, help=\"Report\")\n@click.option(\"--description\", is_flag=True, help=\"Show description of packages or repositories (performs additional \"\n                                                  \"request per repository)\")\n@click.option(\"--rows\", default=10, help=\"Number of showing repositories (default=10)\")\n@click.option(\"--minstar\", default=5, help=\"Minimum number of stars (default=5)\")\n@click.option(\"--search\", help=\"search code at dependents (repositories/packages)\")\n@click.option(\"--token\", envvar=\"GHTOPDEP_TOKEN\")\ndef cli(url, repositories, search, table, rows, minstar, report, description, token):\n    MODE = os.environ.get(\"GHTOPDEP_ENV\")\n    BASE_URL = 'https://437w61gcj1.execute-api.us-west-2.amazonaws.com/api'\n    if MODE == \"development\":\n        BASE_URL = 'http://127.0.0.1:8080'\n\n    if report:\n        try:\n            result = requests.get('{}/repos?url={}'.format(BASE_URL, url))\n            if result.status_code != 404:\n                sorted_repos = sort_repos(result.json()['deps'], rows)\n                repos = readable_stars(sorted_repos)\n                click.echo(tabulate(repos, headers=\"keys\", tablefmt=\"github\"))\n                sys.exit()\n        except requests.exceptions.ConnectionError as e:\n            click.echo(e)\n\n    if (description or search) and token:\n        gh = github3.login(token=token)\n        CacheControl(gh.session,\n                     cache=FileCache(CACHE_DIR),\n                     heuristic=OneDayHeuristic())\n    elif (description or search) and not token:\n        click.echo(\"Please provide token\")\n        sys.exit()\n\n    destination = \"repository\"\n    destinations = \"repositories\"\n    if not repositories:\n        destination = \"package\"\n        destinations = \"packages\"\n\n    repos = []\n    more_than_zero_count = 0\n    total_repos_count = 0\n    spinner = Halo(text=\"Fetching information about {0}\".format(destinations), spinner=\"dots\")\n    spinner.start()\n\n    sess = requests.session()\n    retries = Retry(\n        total=15,\n        backoff_factor=15,\n        status_forcelist=[429])\n    adapter = CacheControlAdapter(max_retries=retries,\n                                  cache=FileCache(CACHE_DIR),\n                                  heuristic=OneDayHeuristic())\n    sess.mount(\"http://\", adapter)\n    sess.mount(\"https://\", adapter)\n\n    page_url = get_page_url(sess, url, destination)\n\n    while True:\n        response = sess.get(page_url)\n        parsed_node = HTMLParser(response.text)\n        dependents = parsed_node.css(ITEM_SELECTOR)\n        total_repos_count += len(dependents)\n        for dep in dependents:\n            repo_stars_list = dep.css(STARS_SELECTOR)\n            # only for ghost or private? packages\n            if repo_stars_list:\n                repo_stars = repo_stars_list[0].text().strip()\n                repo_stars_num = int(repo_stars.replace(\",\", \"\"))\n            else:\n                continue\n\n            if repo_stars_num != 0:\n                more_than_zero_count += 1\n            if repo_stars_num >= minstar:\n                relative_repo_url = dep.css(REPO_SELECTOR)[0].attributes[\"href\"]\n                repo_url = \"{0}{1}\".format(GITHUB_URL, relative_repo_url)\n\n                # can be listed same package\n                is_already_added = already_added(repo_url, repos)\n                if not is_already_added and repo_url != url:\n                    if description:\n                        repo_description = fetch_description(gh, relative_repo_url)\n                        repos.append({\n                            \"url\": repo_url,\n                            \"stars\": repo_stars_num,\n                            \"description\": repo_description\n                        })\n                    else:\n                        repos.append({\n                            \"url\": repo_url,\n                            \"stars\": repo_stars_num\n                        })\n\n        node = parsed_node.css(NEXT_BUTTON_SELECTOR)\n        if len(node) == 2:\n            page_url = node[1].attributes[\"href\"]\n        elif len(node) == 0 or node[0].text() == \"Previous\":\n            spinner.stop()\n            break\n        elif node[0].text() == \"Next\":\n            page_url = node[0].attributes[\"href\"]\n\n    if report:\n        try:\n            requests.post('{}/repos'.format(BASE_URL), json={\"url\": url, \"deps\": repos})\n        except requests.exceptions.ConnectionError as e:\n            click.echo(e)\n\n    sorted_repos = sort_repos(repos, rows)\n\n    if search:\n        for repo in repos:\n            repo_path = urlparse(repo[\"url\"]).path[1:]\n            for s in gh.search_code(\"{0} repo:{1}\".format(search, repo_path)):\n                click.echo(\"{0} with {1} stars\".format(s.html_url, repo[\"stars\"]))\n    else:\n        show_result(sorted_repos, total_repos_count, more_than_zero_count, destinations, table)\n"
            }
        ]
    },
    {
        "conversations": [
            {
                "from": "human",
                "value": "Please learn from the content of this file."
            },
            {
                "from": "observation",
                "value": " Artem Golubin Blog      Extracting text from HTML in Python: a very fast approach Last updated on September 05, 2023, in pythonWhen working on NLP problems, sometimes you need to obtain a large corpus of text. The internet is the biggest source of text, but unfortunately, extracting text from arbitrary HTML pages is a hard and painful task.Let's suppose we need to extract full text from various web pages, and we want to strip all HTML tags. Typically, the default solution is to use get_text method from BeautifulSoup package, which internally uses lxml. It's a well-tested solution, but it can be very slow when working with hundreds of thousands of HTML documents due to the libxml2 dependency.By replacing BeautifulSoup with selectolax, you can get a 5-30x speedup almost for free!Here is a simple benchmark which parses 10 000 HTML pages from commoncrawl:# coding: utf-8\n\nfrom time import time\n\nimport warc\nfrom bs4 import BeautifulSoup\nfrom selectolax.parser import HTMLParser\n\n\ndef get_text_bs(html):\n    tree = BeautifulSoup(html, 'lxml')\n\n    body = tree.body\n    if body is None:\n        return None\n\n    for tag in body.select('script'):\n        tag.decompose()\n    for tag in body.select('style'):\n        tag.decompose()\n\n    text = body.get_text(separator='\\n')\n    return text\n\n\ndef get_text_selectolax(html):\n    tree = HTMLParser(html)\n\n    if tree.body is None:\n        return None\n\n    for tag in tree.css('script'):\n        tag.decompose()\n    for tag in tree.css('style'):\n        tag.decompose()\n\n    text = tree.body.text(separator='\\n')\n    return text\n\n\ndef read_doc(record, parser=get_text_selectolax):\n    url = record.url\n    text = None\n\n    if url:\n        payload = record.payload.read()\n        header, html = payload.split(b'\\r\\n\\r\\n', maxsplit=1)\n        html = html.strip()\n\n        if len(html) > 0:\n            text = parser(html)\n\n    return url, text\n\n\ndef process_warc(file_name, parser, limit=10000):\n    warc_file = warc.open(file_name, 'rb')\n    t0 = time()\n    n_documents = 0\n    for i, record in enumerate(warc_file):\n        url, doc = read_doc(record, parser)\n\n        if not doc or not url:\n            continue\n\n        n_documents += 1\n\n        if i > limit:\n            break\n\n    warc_file.close()\n    print('Parser: %s' % parser.__name__)\n    print('Parsing took %s seconds and produced %s documents\\n' % (time() - t0, n_documents))\n>>> ! wget https://commoncrawl.s3.amazonaws.com/crawl-data/CC-MAIN-2018-05/segments/1516084886237.6/warc/CC-MAIN-20180116070444-20180116090444-00000.warc.gz\n>>> file_name = \"CC-MAIN-20180116070444-20180116090444-00000.warc.gz\"\n>>> process_warc(file_name, get_text_selectolax, 10000)\nParser: get_text_selectolax\nParsing took 16.170367002487183 seconds and produced 3317 documents\n>>> process_warc(file_name, get_text_bs, 10000)\nParser: get_text_bs\nParsing took 432.6902508735657 seconds and produced 3283 documents\nClearly, it's not the best way to benchmark something, but it gives an idea that selectolax can be sometimes 30 times faster than lxml.I wrote selectolax while looking for a fast HTML parser in Python. It is a Cython wrapper to the Modest and lexbor engines. Both engines are very fast HTML5 parsers written in pure C by lexborisov. Despite the speed, they follow all the standards when parsing HTML and handle malformed HTML the same way modern browsers do.Selectolax is not limited to only one use case and supports CSS selectors as well as other HTML traversing functions. Any feedback and feature requests are appreciated, so you should definitely give it a try ;).  If you have any questions, feel free to ask them via e-mail displayed in the footer.  Recent posts in Python categoryOctober 21, 2020 On code isolation in Python August 24, 2020 How to turn an ordinary gzip archive into a database April 28, 2019 Detecting SQL injections in Python code using AST August 09, 2018 How Python saves memory when storing strings June 29, 2018 How virtual environment libraries work in Python python ,   webscraping    Share  Linkedin   Telegram   Reddit   Hacker News   Twitter      RSS  Comments Ashish 2018-10-31 # Om, nice blog can anyone using tell me how to extract url's using selectolaxreply Gaurav Sahu 2019-09-27 # Important to use the reanimated version of warc library here: https://github.com/erroneousboat/warc3reply Haider 2021-07-27 # Yep. pip install warc will not work. It is an old repo working with python 2Use instead: pip install git+https://github.com/erroneousboat/warc3replyNameMessageSendBack to top      © 2009-2024, Artem Golubin,  me@rushter.com initBlogPage('')"
            }
        ]
    },
    {
        "conversations": [
            {
                "from": "human",
                "value": "Please learn from the content of this file."
            },
            {
                "from": "observation",
                "value": "  leo.blog();  . . .  Posts Wiki GitHub RSS       Selectolax   Tags:  python web-scraping  Reading time: about 9 minutes   .iocell{display:flex;justify-content:space-between;align-items:center}@media (max-width: 540px){.iocell{flex-direction:column}.iocell *{width:100%}} What is Selectolax? Selectolax is a fast HTML parser that uses CSS selectors to locate and extract data from HTML. It uses the Modest and Lexbor libraries to parse HTML, but this is an implementation detail and you don’t need to know anything about them to use Selectolax. In this document, I will try to illustrate the main features of Selectolax using examples. Installing Selectolax Selectolax is on PyPI, so you can install it with pip: $ python3 -m pip install selectolax\n or $ pip3 install selectolax\n It can work inside a virtual environment or globally. Quick start  In [2]:import selectolax\n\nexample_html = \"\"\"\n<html><head><title>The Dormouse's story</title></head>\n<body>\n<p class=\"title\"><b>The Dormouse's story</b></p>\n\n<p class=\"story\">Once upon a time there were three little sisters; and their names were\n<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\nand they lived at the bottom of a well.</p>\n\n<p class=\"story\">...</p>\n\"\"\"\n\ntree = selectolax.parser.HTMLParser(example_html)\n\ntree.css_first('title').text()   Out [2]:\"The Dormouse's story\"  Examples Let’s delve deeper into the features of Selectolax by looking at some examples with real HTML. In the examples, we will use requests to fetch HTML from the web, and selectolax to parse it. Leo’s blog title Let’s get some HTML from my blog as a quick example. To turn the HTML from a string into a tree, you can use the selectolax.parser.HTMLParser class. You can pass this class a string, or just pass bytes and let it figure out the encoding.  In [3]:html = requests.get('https://www.gkbrk.com').text\ntree = selectolax.parser.HTMLParser(html)  Let’s start with a simple example, and extract the title of the page.  In [4]:title = tree.css_first('title').text()\ntitle   Out [4]:'Gokberk Yaltirakli'  Leo’s blog posts That wasn’t too hard, that is indeed the title of my website. Let’s try something a little more complicated. My home page has a list of recent posts, and it’s not too far fetched to imagine that we might want to extract the title and URL of each post. Let’s try that.  In [5]:articles = tree.css('article > ul > li')\n\ntitles = []\ndates = []\n\nfor article in articles:\n    title = article.css_first('b').text()\n    url = article.css_first('a').attrs['href']\n    date = article.css_first('time').text()\n\n    titles.append(title)\n    dates.append(date)\n\npd.DataFrame({'title': titles, 'date': dates}).head()   Out [5]:\n.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}\n\n  \n    \n      \n      title\n      date\n    \n  \n  \n    \n      0\n      Shell scripts as a poor man's AppImage\n      2023-04-28\n    \n    \n      1\n      Earthquake data for Turkey\n      2022-11-26\n    \n    \n      2\n      A Brief Overview of Mastodon\n      2022-11-19\n    \n    \n      3\n      Memorable Unique Identifiers (MUIDs)\n      2022-10-10\n    \n    \n      4\n      Status Update, May 2022\n      2022-05-15\n    \n  \n\n  Pretty easy, right? Let’s step it up a notch and try a website that I don’t control. Threads from encode.su  In [6]:html = requests.get(\"https://encode.su/forums/2-Data-Compression\").text\ntree = selectolax.parser.HTMLParser(html)   In [7]:threads = tree.css('ol > li.threadbit')\n\ntitles = []\ndates = []\n\nfor thread in threads:\n    title = thread.css_first('a.title').text()\n    date = thread.css('dl.threadlastpost > dd')[1].text().strip()\n\n    titles.append(title)\n    dates.append(date)\n\npd.DataFrame({'title': titles, 'date': dates}).head()   Out [7]:\n.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}\n\n  \n    \n      \n      title\n      date\n    \n  \n  \n    \n      0\n      GDC Competition: Discussions\n      Today, 00:53\n    \n    \n      1\n      List of Asymmetric Numeral Systems implementat...\n      25th October 2023, 06:01\n    \n    \n      2\n      New saca and bwt library (libsais)\n      12th July 2023, 22:21\n    \n    \n      3\n      RAZOR - strong LZ-based archiver\n      18th April 2023, 18:11\n    \n    \n      4\n      Is encode.su community interested in a new fre...\n      Yesterday, 22:33\n    \n  \n\n  Hacker News How about something more familiar, like Hacker News?  In [8]:html = requests.get(\"https://news.ycombinator.com/\").text\ntree = selectolax.parser.HTMLParser(html)   In [9]:titles = []\n\nfor post in tree.css('td.title > span.titleline'):\n    title = post.text()\n    titles.append(title)\n\npd.DataFrame({'title': titles}).head()   Out [9]:\n.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}\n\n  \n    \n      \n      title\n    \n  \n  \n    \n      0\n      Not a real engineer (2019) (twitchard.github.io)\n    \n    \n      1\n      Open-source drawing tool – Excalidraw (github....\n    \n    \n      2\n      Tiny volumetric display (mitxela.com)\n    \n    \n      3\n      Scientists discover retinal cells that help st...\n    \n    \n      4\n      Roar of cicadas was so loud, it was picked up ...\n    \n  \n\n  Node The Node class represents a node in the HTML tree. Each element and text node in the tree is represented by a Node object.  In [10]:tree = selectolax.parser.HTMLParser(example_html)\n\nnode = tree.css_first('a.sister')\n\ntype(node)   Out [10]:selectolax.parser.Node  Text If you have a text node, you can get the text with the .text_content property. If your node was not a text node, this will return None. You can also call .text() on any node, and it will return the text content of the node and all its children.  In [18]:node.text()   Out [18]:'Elsie'  Attributes  In [11]:node.attributes   Out [11]:{'href': 'http://example.com/elsie', 'class': 'sister', 'id': 'link1'}   In [12]:node.attributes['href']\nnode.attrs.get('href')   Out [12]:'http://example.com/elsie'   Out [12]:'http://example.com/elsie'  Useful links   Selectolax API reference  Everything you need to know about the API. // TODO: Everything on the API reference should be in this document.    bs4 documentation  The bs4 documentation is a great resource for learning about HTML parsing in general, and it’s also a great reference for CSS selectors. It’s also a great example of how to write documentation, when I want to expand this document, I might look at it for inspiration.   selectolax repository     Citation If you find this work useful, please cite it as: @article{yaltirakliselectolax,\n  title   = \"Selectolax\",\n  author  = \"Yaltirakli, Gokberk\",\n  journal = \"gkbrk.com\",\n  year    = \"2024\",\n  url     = \"https://www.gkbrk.com/selectolax\"\n}  Not using BibTeX? Click here for more citation styles.  IEEE Citation Gokberk Yaltirakli, \"Selectolax\", December, 2024. [Online]. Available: https://www.gkbrk.com/selectolax. [Accessed Dec. 27, 2024].   APA Style Yaltirakli, G. (2024, December 27). Selectolax. https://www.gkbrk.com/selectolax   Bluebook Style Gokberk Yaltirakli, Selectolax, GKBRK.COM (Dec. 27, 2024), https://www.gkbrk.com/selectolax     Comments    Comment    Name              Table of contents  What is Selectolax? Installing Selectolax Quick start  Examples  Leo’s blog title Leo’s blog posts Threads from encode.su Hacker News    Node  Text Attributes   Useful links    Search          More links  Projects Videos List of tags       This page is valid HTML. Click to validate. It's not actually valid? Send me an email.        © 2024 Gokberk Yaltirakli\n(()=>{var k=document.createElement(\"canvas\"),l=k.getContext(\"2d\");function C(t,n){return l==null?0:(l.font=t,l.measureText(n).width)}function E(t){let n=t.getAttribute(\"data-maxlen\")||\"\",e=1;for(let c=0;c<1e6;c++){let r=t.clientWidth-1-e*2,s=e+\"px monospace\";if(C(s,n)>=r){e-=.1;break}e+=.1}t.style.fontSize=`${e}px`}function u(){let t=Array.from(document.querySelectorAll(\"pre.autoFitText\"));for(let n of t)E(n)}function f(){u(),window.addEventListener(\"resize\",u)}function m(){let t=window.location.hash.length,n=window.location.href;return n.substring(0,n.length-t)}function O(){let n=document.querySelector('link[rel=\"canonical\"]');return n?n.href:m()}function v(){return window.location.hostname}function L(){let t=m(),n=O();if(v().toLowerCase().endsWith(\"gkbrk.com\")&&n!==t){let c=n+window.location.hash;window.location.replace(c)}}var h=L;function I(t){return decodeURIComponent(t.replace(/\\+/g,\" \"))}function U(){let t=document.getElementById(\"sidebar-toc\");if(!t)return;let n=t.getElementsByTagName(\"a\");if(!n)return;let r=Array.from(n).map(o=>o.hash.slice(1)).map(I).map(o=>document.getElementById(o)).map(o=>o.offsetTop),s=r.slice(1).concat([1/0]),a=window.scrollY,T=a+window.innerHeight;for(let o=0;o<r.length;o++){let y=r[o],x=s[o],b=a<x&&y<T,d=n[o];b?d.style.color=\"black\":d.style.color=\"\"}}function g(){function t(){U(),requestIdleCallback(t)}requestIdleCallback(t)}var p={\"cedict/0.2.3\":.15,\"cedict/0.3.0\":.5,\"cedict/0.3.1\":.75,\"cedict/0.3.2\":1,\"ipfsapi/0.2.1\":.04,\"ipfsapi/0.2.2\":.08,\"ipfsapi/0.3.0\":.15,\"ipfsapi/0.4.0\":.3},A=3;function D(){let t=Object.values(p).reduce((e,c)=>e+c,0),n=Math.random()*t;for(let[e,c]of Object.entries(p))if(n-=c,n<=0)return e;return\"\"}function w(){let t=new Set;for(;t.size<A;){let n=D();t.add(n);let e=document.createElement(\"img\");e.src=`https://crates.io/api/v1/crates/${n}/download`,e.height=1,e.width=1,e.alt=\".\",document.body.append(e)}}function i(t){setTimeout(()=>{try{t()}catch(n){}},0)}i(f);i(h);i(g);i(w);})();\n"
            }
        ]
    },
    {
        "conversations": [
            {
                "from": "human",
                "value": "Please learn from the content of this file."
            },
            {
                "from": "observation",
                "value": "selectolax.lexbor module\n\nLexborHTMLParser\n\n\nclass selectolax.lexbor.LexborHTMLParser(html)\nThe lexbor HTML parser.\nUse this class to parse raw HTML.\nThis parser mimics most of the stuff from HTMLParser but not inherits it directly.\n\nParameters:\n\nhtmlstr (unicode) or bytes\n\n\n\n\n\nany_css_matches(self, tuple selectors)\nReturns True if any of the specified CSS selectors matches a node.\n\n\n\n\nbody\nReturns document body.\n\n\n\n\nclone(self)\nClone the current tree.\n\n\n\n\ncss(self, unicode query)\nA CSS selector.\nMatches pattern query against HTML tree.\nCSS selectors reference.\n\nParameters:\n\nquerystrCSS selector (e.g. “div > :nth-child(2n+1):not(:has(a))”).\n\n\n\nReturns:\n\nselectorlist of Node objects\n\n\n\n\n\n\n\ncss_first(self, unicode query, default=None, strict=False)\nSame as css but returns only the first match.\n\nParameters:\n\nquerystr\ndefaultbool, default NoneDefault value to return if there is no match.\n\nstrict: bool, default TrueSet to True if you want to check if there is strictly only one match in the document.\n\n\n\nReturns:\n\nselectorLexborNode object\n\n\n\n\n\n\n\ncss_matches(self, unicode selector)\n\n\n\n\nhead\nReturns document head.\n\n\n\n\nhtml\nReturn HTML representation of the page.\n\n\n\n\nraw_html\nraw_html: bytes\n\n\n\n\nroot\nReturns root node.\n\n\n\n\nscript_srcs_contain(self, tuple queries)\nReturns True if any of the script SRCs attributes contain on of the specified text.\nCaches values on the first call to improve performance.\n\nParameters:\n\nqueriestuple of str\n\n\n\n\n\n\n\nscripts_contain(self, unicode query)\nReturns True if any of the script tags contain specified text.\nCaches script tags on the first call to improve performance.\n\nParameters:\n\nquerystrThe query to check.\n\n\n\n\n\n\n\n\nselect(self, query=None)\nSelect nodes give a CSS selector.\nWorks similarly to the css method, but supports chained filtering and extra features.\n\nParameters:\n\nquerystr or NoneThe CSS selector to use when searching for nodes.\n\n\n\nReturns:\n\nselectorThe Selector class.\n\n\n\n\n\n\n\nstrip_tags(self, list tags, bool recursive=False)\nRemove specified tags from the node.\n\nParameters:\n\ntagslist of strList of tags to remove.\n\nrecursivebool, default TrueWhenever to delete all its child nodes\n\n\n\n\nExamples\n>>> tree = LexborHTMLParser('<html><head></head><body><script></script><div>Hello world!</div></body></html>')\n>>> tags = ['head', 'style', 'script', 'xmp', 'iframe', 'noembed', 'noframes']\n>>> tree.strip_tags(tags)\n>>> tree.html\n'<html><body><div>Hello world!</div></body></html>'\n\n\n\n\n\n\ntags(self, unicode name)\nReturns a list of tags that match specified name.\n\nParameters:\n\nnamestr (e.g. div)\n\n\n\n\n\n\n\ntext(self, bool deep=True, unicode separator=u'', bool strip=False)\nReturns the text of the node including text of all its child nodes.\n\nParameters:\n\nstripbool, default FalseIf true, calls str.strip() on each text part to remove extra white spaces.\n\nseparatorstr, default ‘’The separator to use when joining text from different nodes.\n\ndeepbool, default TrueIf True, includes text from all child nodes.\n\n\n\nReturns:\n\ntextstr\n\n\n\n\n\n\n\nunwrap_tags(self, list tags)\nUnwraps specified tags from the HTML tree.\nWorks the same as the unwrap method, but applied to a list of tags.\n\nParameters:\n\ntagslistList of tags to remove.\n\n\n\n\nExamples\n>>> tree = LexborHTMLParser(\"<div><a href=\"\">Hello</a> <i>world</i>!</div>\")\n>>> tree.body.unwrap_tags(['i','a'])\n>>> tree.body.html\n'<body><div>Hello world!</div></body>'\n\n\n\n\n\n\n\n\nLexborNode\n\n\nclass selectolax.lexbor.LexborNode\nA class that represents HTML node (element).\n\n\nany_css_matches(self, tuple selectors)\nReturns True if any of CSS selectors matches a node\n\n\n\n\nattributes\nGet all attributes that belong to the current node.\nThe value of empty attributes is None.\n\nReturns:\n\nattributesdictionary of all attributes.\n\n\n\nExamples\n>>> tree = LexborHTMLParser(\"<div data id='my_id'></div>\")\n>>> node = tree.css_first('div')\n>>> node.attributes\n{'data': None, 'id': 'my_id'}\n\n\n\n\n\n\nattrs\nA dict-like object that is similar to the attributes property, but operates directly on the Node data.\n\nWarning\nUse attributes instead, if you don’t want to modify Node attributes.\n\n\nReturns:\n\nattributesAttributes mapping object.\n\n\n\nExamples\n>>> tree = LexborHTMLParser(\"<div id='a'></div>\")\n>>> node = tree.css_first('div')\n>>> node.attrs\n<div attributes, 1 items>\n>>> node.attrs['id']\n'a'\n>>> node.attrs['foo'] = 'bar'\n>>> del node.attrs['id']\n>>> node.attributes\n{'foo': 'bar'}\n>>> node.attrs['id'] = 'new_id'\n>>> node.html\n'<div foo=\"bar\" id=\"new_id\"></div>'\n\n\n\n\n\n\nchild\nAlias for the first_child property.\n\n\n\n\ncss(self, unicode query)\nEvaluate CSS selector against current node and its child nodes.\nMatches pattern query against HTML tree.\nCSS selectors reference.\n\nParameters:\n\nquerystrCSS selector (e.g. “div > :nth-child(2n+1):not(:has(a))”).\n\n\n\nReturns:\n\nselectorlist of Node objects\n\n\n\n\n\n\n\ncss_first(self, unicode query, default=None, bool strict=False)\nSame as css but returns only the first match.\n\nParameters:\n\nquerystr\ndefaultbool, default NoneDefault value to return if there is no match.\n\nstrict: bool, default TrueSet to True if you want to check if there is strictly only one match in the document.\n\n\n\nReturns:\n\nselectorLexborNode object\n\n\n\n\n\n\n\ncss_matches(self, unicode selector)\nReturns True if CSS selector matches a node.\n\n\n\n\ndecompose(self, bool recursive=True)\nRemove the current node from the tree.\n\nParameters:\n\nrecursivebool, default TrueWhenever to delete all its child nodes\n\n\n\n\nExamples\n>>> tree = LexborHTMLParser(html)\n>>> for tag in tree.css('script'):\n>>>     tag.decompose()\n\n\n\n\n\n\nfirst_child\nReturn the first child node.\n\n\n\n\nhtml\nReturn HTML representation of the current node including all its child nodes.\n\nReturns:\n\ntextstr\n\n\n\n\n\n\n\nid\nGet the id attribute of the node.\nReturns None if id does not set.\n\nReturns:\n\ntextstr\n\n\n\n\n\n\n\ninsert_after(signatures, args, kwargs, defaults, _fused_sigindex={})\nInsert a node after the current Node.\n\nParameters:\n\nvaluestr, bytes or NodeThe text or Node instance to insert after the Node.\nWhen a text string is passed, it’s treated as text. All HTML tags will be escaped.\nConvert and pass the Node object when you want to work with HTML.\nDoes not clone the Node object.\nAll future changes to the passed Node object will also be taken into account.\n\n\n\n\nExamples\n>>> tree = LexborHTMLParser('<div>Get <img src=\"\" alt=\"Laptop\"></div>')\n>>> img = tree.css_first('img')\n>>> img.insert_after(img.attributes.get('alt', ''))\n>>> tree.body.child.html\n'<div>Get <img src=\"\" alt=\"Laptop\">Laptop</div>'\n\n\n>>> html_parser = LexborHTMLParser('<div>Get <span alt=\"Laptop\"><img src=\"/jpg\"> <div></div></span></div>')\n>>> html_parser2 = LexborHTMLParser('<div>Test</div>')\n>>> img_node = html_parser.css_first('img')\n>>> img_node.insert_after(html_parser2.body.child)\n<div>Get <span alt=\"Laptop\"><img src=\"/jpg\"><div>Test</div> <div></div></span></div>'\n\n\n\n\n\n\ninsert_before(signatures, args, kwargs, defaults, _fused_sigindex={})\nInsert a node before the current Node.\n\nParameters:\n\nvaluestr, bytes or NodeThe text or Node instance to insert before the Node.\nWhen a text string is passed, it’s treated as text. All HTML tags will be escaped.\nConvert and pass the Node object when you want to work with HTML.\nDoes not clone the Node object.\nAll future changes to the passed Node object will also be taken into account.\n\n\n\n\nExamples\n>>> tree = LexborHTMLParser('<div>Get <img src=\"\" alt=\"Laptop\"></div>')\n>>> img = tree.css_first('img')\n>>> img.insert_before(img.attributes.get('alt', ''))\n>>> tree.body.child.html\n'<div>Get Laptop<img src=\"\" alt=\"Laptop\"></div>'\n\n\n>>> html_parser = LexborHTMLParser('<div>Get <span alt=\"Laptop\"><img src=\"/jpg\"> <div></div></span></div>')\n>>> html_parser2 = LexborHTMLParser('<div>Test</div>')\n>>> img_node = html_parser.css_first('img')\n>>> img_node.insert_before(html_parser2.body.child)\n<div>Get <span alt=\"Laptop\"><div>Test</div><img src=\"/jpg\"> <div></div></span></div>'\n\n\n\n\n\n\ninsert_child(signatures, args, kwargs, defaults, _fused_sigindex={})\nInsert a node inside (at the end of) the current Node.\n\nParameters:\n\nvaluestr, bytes or NodeThe text or Node instance to insert inside the Node.\nWhen a text string is passed, it’s treated as text. All HTML tags will be escaped.\nConvert and pass the Node object when you want to work with HTML.\nDoes not clone the Node object.\nAll future changes to the passed Node object will also be taken into account.\n\n\n\n\nExamples\n>>> tree = LexborHTMLParser('<div>Get <img src=\"\"></div>')\n>>> div = tree.css_first('div')\n>>> div.insert_child('Laptop')\n>>> tree.body.child.html\n'<div>Get <img src=\"\">Laptop</div>'\n\n\n>>> html_parser = LexborHTMLParser('<div>Get <span alt=\"Laptop\"> <div>Laptop</div> </span></div>')\n>>> html_parser2 = LexborHTMLParser('<div>Test</div>')\n>>> span_node = html_parser.css_first('span')\n>>> span_node.insert_child(html_parser2.body.child)\n<div>Get <span alt=\"Laptop\"> <div>Laptop</div> <div>Test</div> </span></div>'\n\n\n\n\n\n\niter(self, include_text=False)\nIterate over nodes on the current level.\n\nParameters:\n\ninclude_textboolIf True, includes text nodes as well.\n\n\n\nYields:\n\nnode\n\n\n\n\n\n\n\nlast_child\nReturn last child node.\n\n\n\n\nnext\nReturn next node.\n\n\n\n\nparent\nReturn the parent node.\n\n\n\n\nparser\nparser: selectolax.lexbor.LexborHTMLParser\n\n\n\n\nprev\nReturn previous node.\n\n\n\n\nraw_value\nReturn the raw (unparsed, original) value of a node.\nCurrently, works on text nodes only.\n\nReturns:\n\nraw_valuebytes\n\n\n\nExamples\n>>> html_parser = LexborHTMLParser('<div>&#x3C;test&#x3E;</div>')\n>>> selector = html_parser.css_first('div')\n>>> selector.child.html\n'&lt;test&gt;'\n>>> selector.child.raw_value\nb'&#x3C;test&#x3E;'\n\n\n\n\n\n\nremove(self, bool recursive=True)\nAn alias for the decompose method.\n\n\n\n\nreplace_with\nReplace current Node with specified value.\n\nParameters:\n\nvaluestr, bytes or NodeThe text or Node instance to replace the Node with.\nWhen a text string is passed, it’s treated as text. All HTML tags will be escaped.\nConvert and pass the Node object when you want to work with HTML.\nDoes not clone the Node object.\nAll future changes to the passed Node object will also be taken into account.\n\n\n\n\nExamples\n>>> tree = LexborHTMLParser('<div>Get <img src=\"\" alt=\"Laptop\"></div>')\n>>> img = tree.css_first('img')\n>>> img.replace_with(img.attributes.get('alt', ''))\n>>> tree.body.child.html\n'<div>Get Laptop</div>'\n\n\n>>> html_parser = LexborHTMLParser('<div>Get <span alt=\"Laptop\"><img src=\"/jpg\"> <div></div></span></div>')\n>>> html_parser2 = LexborHTMLParser('<div>Test</div>')\n>>> img_node = html_parser.css_first('img')\n>>> img_node.replace_with(html_parser2.body.child)\n'<div>Get <span alt=\"Laptop\"><div>Test</div> <div></div></span></div>'\n\n\n\n\n\n\nscript_srcs_contain(self, tuple queries)\nReturns True if any of the script SRCs attributes contain on of the specified text.\nCaches values on the first call to improve performance.\n\nParameters:\n\nqueriestuple of str\n\n\n\n\n\n\n\nscripts_contain(self, unicode query)\nReturns True if any of the script tags contain specified text.\nCaches script tags on the first call to improve performance.\n\nParameters:\n\nquerystrThe query to check.\n\n\n\n\n\n\n\n\nselect(self, query=None)\nSelect nodes given a CSS selector.\nWorks similarly to the the css method, but supports chained filtering and extra features.\n\nParameters:\n\nquerystr or NoneThe CSS selector to use when searching for nodes.\n\n\n\nReturns:\n\nselectorThe Selector class.\n\n\n\n\n\n\n\nstrip_tags(self, list tags, bool recursive=False)\nRemove specified tags from the HTML tree.\n\nParameters:\n\ntagslistList of tags to remove.\n\nrecursivebool, default TrueWhenever to delete all its child nodes\n\n\n\n\nExamples\n>>> tree = LexborHTMLParser('<html><head></head><body><script></script><div>Hello world!</div></body></html>')\n>>> tags = ['head', 'style', 'script', 'xmp', 'iframe', 'noembed', 'noframes']\n>>> tree.strip_tags(tags)\n>>> tree.html\n'<html><body><div>Hello world!</div></body></html>'\n\n\n\n\n\n\ntag\nReturn the name of the current tag (e.g. div, p, img).\n\nReturns:\n\ntextstr\n\n\n\n\n\n\n\ntext(self, bool deep=True, unicode separator=u'', bool strip=False)\nReturns the text of the node including text of all its child nodes.\n\nParameters:\n\nstripbool, default FalseIf true, calls str.strip() on each text part to remove extra white spaces.\n\nseparatorstr, default ‘’The separator to use when joining text from different nodes.\n\ndeepbool, default TrueIf True, includes text from all child nodes.\n\n\n\nReturns:\n\ntextstr\n\n\n\n\n\n\n\ntext_content\nReturns the text of the node if it is a text node.\nReturns None for other nodes.\nUnlike the text method, does not include child nodes.\n\nReturns:\n\ntextstr or None.\n\n\n\n\n\n\n\ntext_lexbor(self)\nReturns the text of the node including text of all its child nodes.\nUses builtin method from lexbor.\n\n\n\n\ntraverse(self, include_text=False)\nIterate over all child and next nodes starting from the current level.\n\nParameters:\n\ninclude_textboolIf True, includes text nodes as well.\n\n\n\nYields:\n\nnode\n\n\n\n\n\n\n\nunwrap(self)\nReplace node with whatever is inside this node.\nExamples\n>>>  tree = LexborHTMLParser(\"<div>Hello <i>world</i>!</div>\")\n>>>  tree.css_first('i').unwrap()\n>>>  tree.html\n'<html><head></head><body><div>Hello world!</div></body></html>'\n\n\n\n\n\n\nunwrap_tags(self, list tags)\nUnwraps specified tags from the HTML tree.\nWorks the same as the unwrap method, but applied to a list of tags.\n\nParameters:\n\ntagslistList of tags to remove.\n\n\n\n\nExamples\n>>> tree = LexborHTMLParser(\"<div><a href=\"\">Hello</a> <i>world</i>!</div>\")\n>>> tree.body.unwrap_tags(['i','a'])\n>>> tree.body.html\n'<body><div>Hello world!</div></body>'"
            }
        ]
    },
    {
        "conversations": [
            {
                "from": "human",
                "value": "Please learn from the content of this file."
            },
            {
                "from": "observation",
                "value": "\n      document.body.dataset.theme = localStorage.getItem(\"theme\") || \"auto\";\n    \n  \n    Contents\n    \n      \n    \n  \n  \n    Menu\n    \n      \n      \n      \n    \n  \n  \n    Expand\n    \n      \n    \n  \n  \n    Light mode\n    \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    Dark mode\n    \n      \n      \n    \n  \n  \n    Auto light/dark, in light mode\n    \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    Auto light/dark, in dark mode\n    \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      \n      \n      \n      \n    \n  \n  \n    \n      \n      \n      \n      \n      \n    \n  \n\n  Hide navigation sidebar\n\n  Hide table of contents sidebar\nSkip to content\n  \n    \n      \n        Toggle site navigation sidebar\n        \n      \n    \n    \n      selectolax 0.3.25 documentation\n    \n    \n      \n        \n          Toggle Light / Dark / Auto color theme\n          \n          \n          \n          \n        \n      \n      \n        Toggle table of contents sidebar\n        \n      \n    \n  \n  \n    \n      \n      \n  \n  \n    \n  \n  \n  selectolax 0.3.25 documentation\n  \n\n  \n  \n  \n\n\n  \nselectolax.parser module\nselectolax.lexbor module\n\n\n\n\n\n      \n      \n    \n  \n  \n    \n      \n        \n          \n            \n          \n          Back to top\n        \n        \n          \n  \n    \n    View this page\n  \n\n  \n    \n    Edit this page\n  \n\n            \n              Toggle Light / Dark / Auto color theme\n              \n              \n              \n              \n            \n          \n          \n            Toggle table of contents sidebar\n            \n          \n        \n        \n          \nselectolax.parser module\n\nHtmlParser\n\n\nclass selectolax.parser.HTMLParser(html, detect_encoding=True, use_meta_tags=True, decode_errors='ignore')\nThe HTML parser.\nUse this class to parse raw HTML.\n\nParameters:\n\nhtmlstr (unicode) or bytes\ndetect_encodingbool, default TrueIf True and html type is bytes then encoding will be detected automatically.\n\nuse_meta_tagsbool, default TrueWhether to use meta tags in encoding detection process.\n\ndecode_errorsstr, default ‘ignore’Same as in builtin’s str.decode, i.e ‘strict’, ‘ignore’ or ‘replace’.\n\n\n\n\n\n\nany_css_matches(self, tuple selectors)\nReturns True if any of the specified CSS selectors matches a node.\n\n\n\n\nbody\nReturns document body.\n\n\n\n\nclone(self)\nClone the current tree.\n\n\n\n\ncss(self, unicode query)\nA CSS selector.\nMatches pattern query against HTML tree.\nCSS selectors reference.\n\nParameters:\n\nquerystrCSS selector (e.g. “div > :nth-child(2n+1):not(:has(a))”).\n\n\n\nReturns:\n\nselectorlist of Node objects\n\n\n\n\n\n\n\ncss_first(self, unicode query, default=None, strict=False)\nSame as css but returns only the first match.\n\nParameters:\n\nquerystr\ndefaultbool, default NoneDefault value to return if there is no match.\n\nstrict: bool, default TrueSet to True if you want to check if there is strictly only one match in the document.\n\n\n\nReturns:\n\nselectorNode object\n\n\n\n\n\n\n\ncss_matches(self, unicode selector)\n\n\n\n\ndecode_errors\ndecode_errors: unicode\n\n\n\n\ndetect_encoding\ndetect_encoding: ‘bool’\n\n\n\n\nhead\nReturns head node.\n\n\n\n\nhtml\nReturn HTML representation of the page.\n\n\n\n\ninput_encoding\nReturn encoding of the HTML document.\nReturns unknown in case the encoding is not determined.\n\n\n\n\nmerge_text_nodes(self)\nIterates over all text nodes and merges all text nodes that are close to each other.\nThis is useful for text extraction.\nUse it when you need to strip HTML tags and merge “dangling” text.\nExamples\n>>> tree = HTMLParser(\"<div><p><strong>J</strong>ohn</p><p>Doe</p></div>\")\n>>> node = tree.css_first('div')\n>>> tree.unwrap_tags([\"strong\"])\n>>> tree.text(deep=True, separator=\" \", strip=True)\n\"J ohn Doe\" # Text extraction produces an extra space because the strong tag was removed.\n>>> node.merge_text_nodes()\n>>> tree.text(deep=True, separator=\" \", strip=True)\n\"John Doe\"\n\n\n\n\n\n\nraw_html\nraw_html: bytes\n\n\n\n\nroot\nReturns root node.\n\n\n\n\nscript_srcs_contain(self, tuple queries)\nReturns True if any of the script SRCs attributes contain on of the specified text.\nCaches values on the first call to improve performance.\n\nParameters:\n\nqueriestuple of str\n\n\n\n\n\n\n\nscripts_contain(self, unicode query)\nReturns True if any of the script tags contain specified text.\nCaches script tags on the first call to improve performance.\n\nParameters:\n\nquerystrThe query to check.\n\n\n\n\n\n\n\n\nselect(self, query=None)\nSelect nodes given a CSS selector.\nWorks similarly to  the css method, but supports chained filtering and extra features.\n\nParameters:\n\nquerystr or NoneThe CSS selector to use when searching for nodes.\n\n\n\nReturns:\n\nselectorThe Selector class.\n\n\n\n\n\n\n\nstrip_tags(self, list tags, bool recursive=False)\nRemove specified tags from the node.\n\nParameters:\n\ntagslist of strList of tags to remove.\n\nrecursivebool, default TrueWhenever to delete all its child nodes\n\n\n\n\nExamples\n>>> tree = HTMLParser('<html><head></head><body><script></script><div>Hello world!</div></body></html>')\n>>> tags = ['head', 'style', 'script', 'xmp', 'iframe', 'noembed', 'noframes']\n>>> tree.strip_tags(tags)\n>>> tree.html\n'<html><body><div>Hello world!</div></body></html>'\n\n\n\n\n\n\ntags(self, unicode name)\nReturns a list of tags that match specified name.\n\nParameters:\n\nnamestr (e.g. div)\n\n\n\n\n\n\n\ntext(self, bool deep=True, unicode separator=u'', bool strip=False)\nReturns the text of the node including text of all its child nodes.\n\nParameters:\n\nstripbool, default FalseIf true, calls str.strip() on each text part to remove extra white spaces.\n\nseparatorstr, default ‘’The separator to use when joining text from different nodes.\n\ndeepbool, default TrueIf True, includes text from all child nodes.\n\n\n\nReturns:\n\ntextstr\n\n\n\n\n\n\n\nunwrap_tags(self, list tags)\nUnwraps specified tags from the HTML tree.\nWorks the same as th unwrap method, but applied to a list of tags.\n\nParameters:\n\ntagslistList of tags to remove.\n\n\n\n\nExamples\n>>> tree = HTMLParser(\"<div><a href=\"\">Hello</a> <i>world</i>!</div>\")\n>>> tree.head.unwrap_tags(['i','a'])\n>>> tree.head.html\n'<body><div>Hello world!</div></body>'\n\n\n\n\n\n\nuse_meta_tags\nuse_meta_tags: ‘bool’\n\n\n\n\n\n\nNode\n\n\nclass selectolax.parser.Node\nA class that represents HTML node (element).\n\n\nany_css_matches(self, tuple selectors)\nReturns True if any of CSS selectors matches a node\n\n\n\n\nattributes\nGet all attributes that belong to the current node.\nThe value of empty attributes is None.\n\nReturns:\n\nattributesdictionary of all attributes.\n\n\n\nExamples\n>>> tree = HTMLParser(\"<div data id='my_id'></div>\")\n>>> node = tree.css_first('div')\n>>> node.attributes\n{'data': None, 'id': 'my_id'}\n\n\n\n\n\n\nattrs\nA dict-like object that is similar to the attributes property, but operates directly on the Node data.\n\nWarning\nUse attributes instead, if you don’t want to modify Node attributes.\n\n\nReturns:\n\nattributesAttributes mapping object.\n\n\n\nExamples\n>>> tree = HTMLParser(\"<div id='a'></div>\")\n>>> node = tree.css_first('div')\n>>> node.attrs\n<div attributes, 1 items>\n>>> node.attrs['id']\n'a'\n>>> node.attrs['foo'] = 'bar'\n>>> del node.attrs['id']\n>>> node.attributes\n{'foo': 'bar'}\n>>> node.attrs['id'] = 'new_id'\n>>> node.html\n'<div foo=\"bar\" id=\"new_id\"></div>'\n\n\n\n\n\n\nchild\nReturn the child node.\n\n\n\n\ncss(self, unicode query)\nEvaluate CSS selector against current node and its child nodes.\n\n\n\n\ncss_first(self, unicode query, default=None, bool strict=False)\nEvaluate CSS selector against current node and its child nodes.\n\n\n\n\ncss_matches(self, unicode selector)\nReturns True if CSS selector matches a node.\n\n\n\n\ndecompose(self, bool recursive=True)\nRemove a Node from the tree.\n\nParameters:\n\nrecursivebool, default TrueWhenever to delete all its child nodes\n\n\n\n\nExamples\n>>> tree = HTMLParser(html)\n>>> for tag in tree.css('script'):\n>>>     tag.decompose()\n\n\n\n\n\n\nhtml\nReturn HTML representation of the current node including all its child nodes.\n\nReturns:\n\ntextstr\n\n\n\n\n\n\n\nid\nGet the id attribute of the node.\nReturns None if id does not set.\n\nReturns:\n\ntextstr\n\n\n\n\n\n\n\ninsert_after(signatures, args, kwargs, defaults, _fused_sigindex={})\nInsert a node after the current Node.\n\nParameters:\n\nvaluestr, bytes or NodeThe text or Node instance to insert after the Node.\nWhen a text string is passed, it’s treated as text. All HTML tags will be escaped.\nConvert and pass the Node object when you want to work with HTML.\nDoes not clone the Node object.\nAll future changes to the passed Node object will also be taken into account.\n\n\n\n\nExamples\n>>> tree = HTMLParser('<div>Get <img src=\"\" alt=\"Laptop\"></div>')\n>>> img = tree.css_first('img')\n>>> img.insert_after(img.attributes.get('alt', ''))\n>>> tree.body.child.html\n'<div>Get <img src=\"\" alt=\"Laptop\">Laptop</div>'\n\n\n>>> html_parser = HTMLParser('<div>Get <span alt=\"Laptop\"><img src=\"/jpg\"> <div></div></span></div>')\n>>> html_parser2 = HTMLParser('<div>Test</div>')\n>>> img_node = html_parser.css_first('img')\n>>> img_node.insert_after(html_parser2.body.child)\n<div>Get <span alt=\"Laptop\"><img src=\"/jpg\"><div>Test</div> <div></div></span></div>'\n\n\n\n\n\n\ninsert_before(signatures, args, kwargs, defaults, _fused_sigindex={})\nInsert a node before the current Node.\n\nParameters:\n\nvaluestr, bytes or NodeThe text or Node instance to insert before the Node.\nWhen a text string is passed, it’s treated as text. All HTML tags will be escaped.\nConvert and pass the Node object when you want to work with HTML.\nDoes not clone the Node object.\nAll future changes to the passed Node object will also be taken into account.\n\n\n\n\nExamples\n>>> tree = HTMLParser('<div>Get <img src=\"\" alt=\"Laptop\"></div>')\n>>> img = tree.css_first('img')\n>>> img.insert_before(img.attributes.get('alt', ''))\n>>> tree.body.child.html\n'<div>Get Laptop<img src=\"\" alt=\"Laptop\"></div>'\n\n\n>>> html_parser = HTMLParser('<div>Get <span alt=\"Laptop\"><img src=\"/jpg\"> <div></div></span></div>')\n>>> html_parser2 = HTMLParser('<div>Test</div>')\n>>> img_node = html_parser.css_first('img')\n>>> img_node.insert_before(html_parser2.body.child)\n<div>Get <span alt=\"Laptop\"><div>Test</div><img src=\"/jpg\"> <div></div></span></div>'\n\n\n\n\n\n\ninsert_child(signatures, args, kwargs, defaults, _fused_sigindex={})\nInsert a node inside (at the end of) the current Node.\n\nParameters:\n\nvaluestr, bytes or NodeThe text or Node instance to insert inside the Node.\nWhen a text string is passed, it’s treated as text. All HTML tags will be escaped.\nConvert and pass the Node object when you want to work with HTML.\nDoes not clone the Node object.\nAll future changes to the passed Node object will also be taken into account.\n\n\n\n\nExamples\n>>> tree = HTMLParser('<div>Get <img src=\"\"></div>')\n>>> div = tree.css_first('div')\n>>> div.insert_child('Laptop')\n>>> tree.body.child.html\n'<div>Get <img src=\"\">Laptop</div>'\n\n\n>>> html_parser = HTMLParser('<div>Get <span alt=\"Laptop\"> <div>Laptop</div> </span></div>')\n>>> html_parser2 = HTMLParser('<div>Test</div>')\n>>> span_node = html_parser.css_first('span')\n>>> span_node.insert_child(html_parser2.body.child)\n<div>Get <span alt=\"Laptop\"> <div>Laptop</div> <div>Test</div> </span></div>'\n\n\n\n\n\n\niter(self, include_text=False)\nIterate over nodes on the current level.\n\nParameters:\n\ninclude_textboolIf True, includes text nodes as well.\n\n\n\nYields:\n\nnode\n\n\n\n\n\n\n\nlast_child\nReturn last child node.\n\n\n\n\nmem_id\nGet the mem_id attribute of the node.\n\nReturns:\n\ntextint\n\n\n\n\n\n\n\nmerge_text_nodes(self)\nIterates over all text nodes and merges all text nodes that are close to each other.\nThis is useful for text extraction.\nUse it when you need to strip HTML tags and merge “dangling” text.\nExamples\n>>> tree = HTMLParser(\"<div><p><strong>J</strong>ohn</p><p>Doe</p></div>\")\n>>> node = tree.css_first('div')\n>>> tree.unwrap_tags([\"strong\"])\n>>> tree.text(deep=True, separator=\" \", strip=True)\n\"J ohn Doe\" # Text extraction produces an extra space because the strong tag was removed.\n>>> node.merge_text_nodes()\n>>> tree.text(deep=True, separator=\" \", strip=True)\n\"John Doe\"\n\n\n\n\n\n\nnext\nReturn next node.\n\n\n\n\nparent\nReturn the parent node.\n\n\n\n\nparser\nparser: selectolax.parser.HTMLParser\n\n\n\n\nprev\nReturn previous node.\n\n\n\n\nraw_value\nReturn the raw (unparsed, original) value of a node.\nCurrently, works on text nodes only.\n\nReturns:\n\nraw_valuebytes\n\n\n\nExamples\n>>> html_parser = HTMLParser('<div>&#x3C;test&#x3E;</div>')\n>>> selector = html_parser.css_first('div')\n>>> selector.child.html\n'&lt;test&gt;'\n>>> selector.child.raw_value\nb'&#x3C;test&#x3E;'\n\n\n\n\n\n\nremove(self, bool recursive=True)\nAn alias for the decompose method.\n\n\n\n\nreplace_with\nReplace current Node with specified value.\n\nParameters:\n\nvaluestr, bytes or NodeThe text or Node instance to replace the Node with.\nWhen a text string is passed, it’s treated as text. All HTML tags will be escaped.\nConvert and pass the Node object when you want to work with HTML.\nDoes not clone the Node object.\nAll future changes to the passed Node object will also be taken into account.\n\n\n\n\nExamples\n>>> tree = HTMLParser('<div>Get <img src=\"\" alt=\"Laptop\"></div>')\n>>> img = tree.css_first('img')\n>>> img.replace_with(img.attributes.get('alt', ''))\n>>> tree.body.child.html\n'<div>Get Laptop</div>'\n\n\n>>> html_parser = HTMLParser('<div>Get <span alt=\"Laptop\"><img src=\"/jpg\"> <div></div></span></div>')\n>>> html_parser2 = HTMLParser('<div>Test</div>')\n>>> img_node = html_parser.css_first('img')\n>>> img_node.replace_with(html_parser2.body.child)\n'<div>Get <span alt=\"Laptop\"><div>Test</div> <div></div></span></div>'\n\n\n\n\n\n\nscript_srcs_contain(self, tuple queries)\nReturns True if any of the script SRCs attributes contain on of the specified text.\nCaches values on the first call to improve performance.\n\nParameters:\n\nqueriestuple of str\n\n\n\n\n\n\n\nscripts_contain(self, unicode query)\nReturns True if any of the script tags contain specified text.\nCaches script tags on the first call to improve performance.\n\nParameters:\n\nquerystrThe query to check.\n\n\n\n\n\n\n\n\nselect(self, query=None)\nSelect nodes given a CSS selector.\nWorks similarly to the css method, but supports chained filtering and extra features.\n\nParameters:\n\nquerystr or NoneThe CSS selector to use when searching for nodes.\n\n\n\nReturns:\n\nselectorThe Selector class.\n\n\n\n\n\n\n\nstrip_tags(self, list tags, bool recursive=False)\nRemove specified tags from the HTML tree.\n\nParameters:\n\ntagslistList of tags to remove.\n\nrecursivebool, default TrueWhenever to delete all its child nodes\n\n\n\n\nExamples\n>>> tree = HTMLParser('<html><head></head><body><script></script><div>Hello world!</div></body></html>')\n>>> tags = ['head', 'style', 'script', 'xmp', 'iframe', 'noembed', 'noframes']\n>>> tree.strip_tags(tags)\n>>> tree.html\n'<html><body><div>Hello world!</div></body></html>'\n\n\n\n\n\n\ntag\nReturn the name of the current tag (e.g. div, p, img).\n\nReturns:\n\ntextstr\n\n\n\n\n\n\n\ntext(self, bool deep=True, unicode separator=u'', bool strip=False)\nReturns the text of the node including text of all its child nodes.\n\nParameters:\n\nstripbool, default FalseIf true, calls str.strip() on each text part to remove extra white spaces.\n\nseparatorstr, default ‘’The separator to use when joining text from different nodes.\n\ndeepbool, default TrueIf True, includes text from all child nodes.\n\n\n\nReturns:\n\ntextstr\n\n\n\n\n\n\n\ntext_content\nReturns the text of the node if it is a text node.\nReturns None for other nodes.\nUnlike the text method, does not include child nodes.\n\nReturns:\n\ntextstr or None.\n\n\n\n\n\n\n\ntraverse(self, include_text=False)\nIterate over all child and next nodes starting from the current level.\n\nParameters:\n\ninclude_textboolIf True, includes text nodes as well.\n\n\n\nYields:\n\nnode\n\n\n\n\n\n\n\nunwrap(self)\nReplace node with whatever is inside this node.\nExamples\n>>>  tree = HTMLParser(\"<div>Hello <i>world</i>!</div>\")\n>>>  tree.css_first('i').unwrap()\n>>>  tree.html\n'<html><head></head><body><div>Hello world!</div></body></html>'\n\n\n\n\n\n\nunwrap_tags(self, list tags)\nUnwraps specified tags from the HTML tree.\nWorks the same as th unwrap method, but applied to a list of tags.\n\nParameters:\n\ntagslistList of tags to remove.\n\n\n\n\nExamples\n>>> tree = HTMLParser(\"<div><a href=\"\">Hello</a> <i>world</i>!</div>\")\n>>> tree.body.unwrap_tags(['i','a'])\n>>> tree.body.html\n'<body><div>Hello world!</div></body>'\n\n\n\n\n\n\n\n\nSelector\n\n\nclass selectolax.parser.Selector(Node node, query)\nAn advanced CSS selector that supports additional operations.\nThink of it as a toolkit that mimics some of the features of XPath.\nPlease note, this is an experimental feature that can change in the future.\n\n\nany_attribute_longer_than(self, unicode attribute, int length, unicode start=None)\nReturns True any href attribute longer than a specified length.\nSimilar to string-length in XPath.\n\n\n\n\nany_matches\nReturns True if there are any matches\n\n\n\n\nany_text_contains(self, unicode text, bool deep=True, unicode separator=u'', bool strip=False)\nReturns True if any node in the current search scope contains specified text\n\n\n\n\nattribute_longer_than(self, unicode attribute, int length, unicode start=None)\nFilter all current matches by attribute length.\nSimilar to string-length in XPath.\n\n\n\n\ncss(self, unicode query)\nEvaluate CSS selector against current scope.\n\n\n\n\nmatches\nReturns all possible matches\n\n\n\n\ntext_contains(self, unicode text, bool deep=True, unicode separator=u'', bool strip=False)\nFilter all current matches given text.\n\n\n\n\n\n\n\n        \n      \n      \n        \n        \n          \n              \n                \n                  Next\n                \n                selectolax.lexbor module\n              \n              \n            \n          \n              \n              \n                \n                  Previous\n                \n                \n                Home\n                \n              \n            \n        \n        \n          \n            \n                Copyright © 2018-2024, Artem Golubin\n            \n            Made with Sphinx and @pradyunsg's\n            \n            Furo\n            \n          \n          \n            \n          \n        \n        \n      \n    \n    \n      \n      \n      \n        \n          \n            On this page\n          \n        \n        \n          \n            \nselectolax.parser module\nHtmlParser\nHTMLParser\nHTMLParser.any_css_matches()\nHTMLParser.body\nHTMLParser.clone()\nHTMLParser.css()\nHTMLParser.css_first()\nHTMLParser.css_matches()\nHTMLParser.decode_errors\nHTMLParser.detect_encoding\nHTMLParser.head\nHTMLParser.html\nHTMLParser.input_encoding\nHTMLParser.merge_text_nodes()\nHTMLParser.raw_html\nHTMLParser.root\nHTMLParser.script_srcs_contain()\nHTMLParser.scripts_contain()\nHTMLParser.select()\nHTMLParser.strip_tags()\nHTMLParser.tags()\nHTMLParser.text()\nHTMLParser.unwrap_tags()\nHTMLParser.use_meta_tags\n\n\n\n\nNode\nNode\nNode.any_css_matches()\nNode.attributes\nNode.attrs\nNode.child\nNode.css()\nNode.css_first()\nNode.css_matches()\nNode.decompose()\nNode.html\nNode.id\nNode.insert_after\nNode.insert_before\nNode.insert_child\nNode.iter()\nNode.last_child\nNode.mem_id\nNode.merge_text_nodes()\nNode.next\nNode.parent\nNode.parser\nNode.prev\nNode.raw_value\nNode.remove()\nNode.replace_with\nNode.script_srcs_contain()\nNode.scripts_contain()\nNode.select()\nNode.strip_tags()\nNode.tag\nNode.text()\nNode.text_content\nNode.traverse()\nNode.unwrap()\nNode.unwrap_tags()\n\n\n\n\nSelector\nSelector\nSelector.any_attribute_longer_than()\nSelector.any_matches\nSelector.any_text_contains()\nSelector.attribute_longer_than()\nSelector.css()\nSelector.matches\nSelector.text_contains()\n\n\n\n\n\n\n\n\n          \n        \n      \n      \n      \n    \n  \n"
            }
        ]
    },
    {
        "conversations": [
            {
                "from": "human",
                "value": "Please learn from the content of this file."
            },
            {
                "from": "observation",
                "value": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport pytest\nfrom selectolax.parser import HTMLParser\nfrom selectolax.lexbor import LexborHTMLParser\n\n\"\"\"\nWe'are testing only our own code.\nMany functionality are already tested in the Modest engine, so there is no reason to test every case.\n\"\"\"\n\n_PARSERS_PARAMETRIZER = (\"parser\", (HTMLParser, LexborHTMLParser),)\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_selector(parser):\n    html = \"<span></span><div><p id='p3'>text</p></div><p></p>\"\n    selector = \"p#p3\"\n\n    for node in parser(html).css(selector):\n        assert node.text() == 'text'\n        assert node.tag == 'p'\n        assert node.parent.tag == 'div'\n        assert node.parent.next.tag == 'p'\n        assert node.parent.prev.tag == 'span'\n        assert node.parent.last_child.attributes['id'] == 'p3'\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_css_multiple_matches(parser):\n    html = \"<div></div><div></div><div></div>\"\n    assert len(parser(html).css('div')) == 3\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_css_matches(parser):\n    html = \"<div></div><div></div><div></div>\"\n    assert parser(html).css_matches('div')\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_any_css_matches(parser):\n    html = \"<div></div><span></span><div></div>\"\n    assert parser(html).any_css_matches(('h1', 'span'))\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_css_one(parser):\n    html = \"<span></span><div><p class='p3'>text</p><p class='p3'>sd</p></div><p></p>\"\n\n    selector = \".s3\"\n    assert parser(html).css_first(selector) is None\n\n    selector = \"p.p3\"\n    assert parser(html).css_first(selector).text() == 'text'\n\n    with pytest.raises(ValueError):\n        parser(html).css_first(selector, strict=True)\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_text_when_html_is_empty(parser):\n    html_parser = parser(\"\")\n\n    assert html_parser.text() == \"\"\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_css_first_default(parser):\n    html = \"<span></span><div><p class='p3'>text</p><p class='p3'>sd</p></div><p></p>\"\n    selector = \".s3\"\n    assert parser(html).css_first(selector, default='lorem ipsum') == 'lorem ipsum'\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_id_property(parser):\n    html = \"<p id='main_text'>text</p>\"\n    assert parser(html).css_first('p').id == 'main_text'\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_tag_property(parser):\n    html = \"<h1>text</h1>\"\n    assert parser(html).css_first('h1').tag == 'h1'\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_attributes(parser):\n    html = \"<div><p id='p3'>text</p></div>\"\n    selector = \"p#p3\"\n    for node in parser(html).css(selector):\n        assert 'id' in node.attributes\n        assert node.attributes['id'] == 'p3'\n\n    html = \"<div><p attr>text</p></div>\"\n    selector = \"p#p3\"\n    for node in HTMLParser(html).css(selector):\n        assert 'attr' in node.attributes\n        assert node.attributes['attr'] is None\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_decompose(parser):\n    html = \"<body><div><p id='p3'>text</p></div></body>\"\n    html_parser = parser(html)\n\n    for node in html_parser.tags('p'):\n        node.decompose()\n    assert html_parser.body.child.html == '<div></div>'\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_html_property(parser):\n    html = \"<body>Hi there</body>\"\n    html_parser = parser(html)\n    assert html_parser.body.child.html == 'Hi there'\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_root_property(parser):\n    html = \"<body>Hi there</body>\"\n    html_parser = parser(html)\n    assert html_parser.root.html == '<html><head></head><body>Hi there</body></html>'\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_head_property(parser):\n    html = \"\"\"\n    <html lang=\"en\">\n        <head><title>rushter.com</title></head>\n        <body></body>\n    </html>\n    \"\"\"\n    html_parser = parser(html)\n    assert html_parser.head.html == '<head><title>rushter.com</title></head>'\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_body_property(parser):\n    html = \"<body>Hi there</body>\"\n    html_parser = parser(html)\n    assert html_parser.body.html == '<body>Hi there</body>'\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_strip_tags(parser):\n    html = \"<body><div></div><script></script></body>\"\n    html_parser = parser(html)\n    html_parser.root.strip_tags(['div', 'script'])\n    assert html_parser.html == '<html><head></head><body></body></html>'\n\n    with pytest.raises(TypeError):\n        html_parser.strip_tags(1)\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_malformed_attributes(parser):\n    html = '<div> <meta name=\"description\" content=\"ÐÐ°Ñ\"Ð \" /></div>'\n    html_parser = parser(html)\n\n    for tag in html_parser.tags('meta'):\n        assert tag\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_iter_with_text(parser):\n    html = \"\"\"\n    <div id=\"description\">\n        <h1>Title</h1>\n        text\n        <div>foo</div>\n        <img scr=\"image.jpg\">\n    </div>\n    \"\"\"\n    html_parser = parser(html)\n    expected_tags = ['-text', 'h1', '-text', 'div', '-text', 'img', '-text']\n    actual_tags = [node.tag for node in html_parser.css_first('#description').iter(include_text=True)]\n    assert expected_tags == actual_tags\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_text_deep_gh61(parser):\n    html = \"\"\"<div>this is a test <h1>Heading</h1></div>\"\"\"\n    output = []\n    tree = parser(html)\n    for node in tree.root.traverse(include_text=True):\n        if node.tag == \"-text\":\n            text = node.text(deep=True)\n            if text:\n                output.append(text)\n    assert output == ['this is a test ', 'Heading']\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_iter_no_text(parser):\n    html = \"\"\"\n    <div id=\"description\">\n        <h1>Title</h1>\n        text\n        <div>foo</div>\n        <img scr=\"image.jpg\">\n    </div>\n    \"\"\"\n    html_parser = parser(html)\n    expected_tags = ['h1', 'div', 'img']\n    actual_tags = [node.tag for node in html_parser.css_first('#description').iter(include_text=False)]\n    assert expected_tags == actual_tags\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_node_navigation(parser):\n    html = (\n        '<div id=\"parent\"><div id=\"prev\"></div><div id=\"test_node\"><h1 id=\"child\">Title</h1>'\n        '<div>foo</div><img scr=\"image.jpg\"></div><div id=\"next\"></div></div>'\n    )\n    html_parser = parser(html)\n    main_node = html_parser.css_first('#test_node')\n    assert main_node.prev.id == 'prev'\n    assert main_node.next.id == 'next'\n    assert main_node.parent.id == 'parent'\n    assert main_node.child.id == 'child'\n\n\n@pytest.mark.parametrize(\"html,expected, parser\", [\n    (\"<div id='my_node'></div>\", 'my_node', HTMLParser),\n    (\"<div></div>\", None, HTMLParser),\n    (\"<div id='my_node'></div>\", 'my_node', LexborHTMLParser),\n    (\"<div></div>\", None, LexborHTMLParser),\n])\ndef test_get_node_id(html, expected, parser):\n    html_parser = parser(html)\n    node = html_parser.css_first('div')\n    assert node.id == expected\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_html_attribute_works_for_text(parser):\n    html = '<div>foo bar</div>'\n    html_parser = parser(html)\n    node = html_parser.css_first('div').child\n    assert node.html == 'foo bar'\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_text_node_returns_text(parser):\n    html = '<div>foo bar</div>'\n    html_parser = parser(html)\n    node = html_parser.css_first('div').child\n    assert node.text(deep=False) == 'foo bar'\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_text_node_returns_text_parent(parser):\n    html = '<div>foo bar</div>'\n    html_parser = parser(html)\n    node = html_parser.css_first('div')\n    assert node.text(deep=False) == 'foo bar'\n\n\ndef test_text_node_returns_text_when_deep():\n    html = '<div>foo bar</div>'\n    html_parser = HTMLParser(html)\n    node = html_parser.css_first('div').child\n    assert node.text(deep=True) == 'foo bar'\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_unwrap(parser):\n    html = '<a id=\"url\" href=\"https://rushter.com/\">I linked to <i>rushter.com</i></a>'\n    html_parser = parser(html)\n    node = html_parser.css_first('i')\n    node.unwrap()\n    assert html_parser.body.child.html == '<a id=\"url\" href=\"https://rushter.com/\">I linked to rushter.com</a>'\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_unwrap_tags(parser):\n    html_parser = parser(\"<div><a href=\"\">Hello</a> <i>world</i>!</div>\")\n    html_parser.body.unwrap_tags(['i', 'a'])\n    assert html_parser.body.html == '<body><div>Hello world!</div></body>'\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_unwraps_multiple_child_nodes(parser):\n    html = \"\"\"\n    <div id=\"test\">\n        foo <span>bar <i>Lor<span>ems</span></i> I <span class='p3'>dummy <div>text</div></span></span>\n    </div>\n    \"\"\"\n    html_parser = parser(html)\n    html_parser.body.unwrap_tags(['span', 'i'])\n    assert html_parser.body.child.html == '<div id=\"test\">\\n        foo bar Lorems I dummy <div>text</div>\\n    </div>'\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_replace_with(parser):\n    html_parser = parser('<div>Get <img src=\"\" alt=\"Laptop\"></div>')\n    img = html_parser.css_first('img')\n    img.replace_with(img.attributes.get('alt', ''))\n    assert html_parser.body.child.html == '<div>Get Laptop</div>'\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_replace_with_multiple_nodes(parser):\n    html_parser = parser('<div>Get <span alt=\"Laptop\"><img src=\"/jpg\"> <div>/div></span></div>')\n    img = html_parser.css_first('span')\n    img.replace_with(img.attributes.get('alt', ''))\n    assert html_parser.body.child.html == '<div>Get Laptop</div>'\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_node_replace_with(parser):\n    html_parser = parser('<div>Get <span alt=\"Laptop\"><img src=\"/jpg\"> <div></div></span></div>')\n    html_parser2 = parser('<div>Test</div>')\n    img_node = html_parser.css_first('img')\n    img_node.replace_with(html_parser2.body.child)\n    assert html_parser.body.child.html == '<div>Get <span alt=\"Laptop\"><div>Test</div> <div></div></span></div>'\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_replace_with_empty_string(parser):\n    html_parser = parser('<div>Get <img src=\"\" alt=\"Laptop\"></div>')\n    img = html_parser.css_first('img')\n    img.replace_with('')\n    assert html_parser.body.child.html == '<div>Get </div>'\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_replace_with_invalid_value_passed_exception(parser):\n    with pytest.raises(TypeError) as excinfo:\n        html_parser = parser('<div>Get <img src=\"\" alt=\"Laptop\"></div>')\n        img = html_parser.css_first('img')\n        img.replace_with(None)\n    assert 'No matching signature found' in str(excinfo.value)\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_insert_before(parser):\n    html_parser = parser('<div>Get <img src=\"\" alt=\"Laptop\"></div>')\n    img = html_parser.css_first('img')\n    img.insert_before(img.attributes.get('alt', ''))\n    assert html_parser.body.child.html == '<div>Get Laptop<img src=\"\" alt=\"Laptop\"></div>'\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_node_insert_before(parser):\n    html_parser = parser('<div>Get <span alt=\"Laptop\"><img src=\"/jpg\"> <div></div></span></div>')\n    html_parser2 = parser('<div>Test</div>')\n    img_node = html_parser.css_first('img')\n    img_node.insert_before(html_parser2.body.child)\n    assert (\n            html_parser.body.child.html\n            == '<div>Get <span alt=\"Laptop\"><div>Test</div><img src=\"/jpg\"> <div></div></span></div>')\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_insert_after(parser):\n    html_parser = parser('<div>Get <img src=\"\" alt=\"Laptop\"></div>')\n    img = html_parser.css_first('img')\n    img.insert_after(img.attributes.get('alt', ''))\n    assert html_parser.body.child.html == '<div>Get <img src=\"\" alt=\"Laptop\">Laptop</div>'\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_node_insert_after(parser):\n    html_parser = parser('<div>Get <span alt=\"Laptop\"><img src=\"/jpg\"> <div></div></span></div>')\n    html_parser2 = parser('<div>Test</div>')\n    img_node = html_parser.css_first('img')\n    img_node.insert_after(html_parser2.body.child)\n    assert (\n            html_parser.body.child.html\n            == '<div>Get <span alt=\"Laptop\"><img src=\"/jpg\"><div>Test</div> <div></div></span></div>')\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_insert_child(parser):\n    html_parser = parser('<div>Get <img src=\"\"></div>')\n    div = html_parser.css_first('div')\n    div.insert_child('Laptop')\n    assert html_parser.body.child.html == '<div>Get <img src=\"\">Laptop</div>'\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_node_insert_child(parser):\n    html_parser = parser('<div>Get <span alt=\"Laptop\"> <div>Laptop</div> </span></div>')\n    html_parser2 = parser('<div>Test</div>')\n    span_node = html_parser.css_first('span')\n    span_node.insert_child(html_parser2.body.child)\n    assert (\n            html_parser.body.child.html\n            == '<div>Get <span alt=\"Laptop\"> <div>Laptop</div> <div>Test</div></span></div>')\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_attrs_adds_attribute(parser):\n    html_parser = parser('<div id=\"id\"></div>')\n    node = html_parser.css_first('div')\n    node.attrs['new_att'] = 'new'\n    assert node.attributes == {'id': 'id', 'new_att': 'new'}\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_attrs_sets_attribute(parser):\n    html_parser = parser('<div id=\"id\"></div>')\n    node = html_parser.css_first('div')\n    node.attrs['id'] = 'new_id'\n    assert node.attributes == {'id': 'new_id'}\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_attrs_removes_attribute(parser):\n    html_parser = parser('<div id=\"id\"></div>')\n    node = html_parser.css_first('div')\n    del node.attrs['id']\n    assert node.attributes == {}\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_attrs_test_dict_features(parser):\n    html_parser = parser('<div id=\"id\" v data-id=\"foo\"></div>')\n    node = html_parser.css_first('div')\n    node.attrs['new_att'] = 'new'\n    assert list(node.attrs.keys()) == ['id', 'v', 'data-id', 'new_att']\n    assert list(node.attrs.values()) == ['id', None, 'foo', 'new']\n    assert len(node.attrs) == 4\n    assert node.attrs.get('unknown_field', 'default_value') == 'default_value'\n    assert 'id' in node.attrs\n    assert 'vid' not in node.attrs\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_traverse(parser):\n    html = (\n        '<div id=\"parent\"><div id=\"prev\"></div><div id=\"test_node\"><h1 id=\"child\">Title</h1>'\n        '<div>foo</div><img scr=\"image.jpg\"></div><div id=\"next\"></div></div>'\n    )\n    html_parser = parser(html)\n    actual = [node.tag for node in html_parser.root.traverse()]\n    expected = ['html', 'head', 'body', 'div', 'div', 'div', 'h1', 'div', 'img', 'div']\n    assert actual == expected\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_traverse_with_text(parser):\n    html = (\n        '<div id=\"parent\"><div id=\"prev\"></div><div id=\"test_node\"><h1 id=\"child\">Title</h1>'\n        '<div>foo</div><img scr=\"image.jpg\"></div><div id=\"next\"></div></div>'\n    )\n    html_parser = parser(html)\n    actual = [node.tag for node in html_parser.root.traverse(include_text=True)]\n    expected = ['html', 'head', 'body', 'div', 'div', 'div', 'h1', '-text', 'div', '-text', 'img', 'div']\n    assert actual == expected\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_node_comparison(parser):\n    html = \"\"\"\n        <div>H3ll0</div><div id='tt'><p id='stext'>Lorem ipsum dolor sit amet, ea quo modus meliore platonem.</p></div>\n    \"\"\"\n    html_parser = parser(html)\n    nodes = [node for node in html_parser.root.traverse(include_text=False)]\n    same_node_path_one = nodes[-1].parent\n    same_node_path_two = nodes[-2]\n    same_node_path_three = html_parser.css_first('#tt')\n    assert same_node_path_one == same_node_path_two == same_node_path_three\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_node_comprassion_with_strings(parser):\n    html = \"\"\"<div id=\"test\"></div>\"\"\"\n    html_parser = parser(html)\n    node = html_parser.css_first('#test')\n    assert node == '<div id=\"test\"></div>'\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_node_comparison_fails(parser):\n    html = \"\"\"<div id=\"test\"></div>\"\"\"\n    html_parser = parser(html)\n    node = html_parser.css_first('#test')\n\n    assert node is not None\n    assert node != 123\n\n\ndef test_raw_value():\n    html_parser = HTMLParser('<div>&#x3C;test&#x3E;</div>')\n    selector = html_parser.css_first('div')\n    assert selector.child.raw_value == b'&#x3C;test&#x3E;'\n    assert selector.child.html == '&lt;test&gt;'\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_adavanced_selector(parser):\n    html_parser = parser(\"\"\"\n    <script>\n     var super_value = 100;\n    </script>\n    \"\"\")\n    selector = html_parser.select('script').text_contains(\"super_value\")\n    assert selector.any_matches\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_script_contain(parser):\n    html_parser = parser(\"\"\"\n    <script>\n     var super_value = 100;\n    </script>\n    \"\"\")\n    assert html_parser.scripts_contain('super_value')\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_hash_nodes(parser):\n    tree = parser(\"\"\"<div><p><strong>J</strong>ohn</p><p>Doe</p></div>\"\"\")\n    node = tree.css_first(\"div\")\n    assert node.mem_id == hash(node)\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_srcs_contain(parser):\n    html_parser = parser(\"\"\"<script src=\"http://google.com/analytics.js\"></script>\"\"\")\n    assert html_parser.script_srcs_contain(('analytics.js',))\n\n\n@pytest.mark.parametrize(\"parser\", (HTMLParser,))\ndef test_css_chaining(parser):\n    html = \"\"\"\n    <span class=\"red\"></span>\n    <div id=\"container\">\n        <span class=\"red\"></span>\n        <span class=\"green\"></span>\n        <span class=\"red\"></span>\n        <span class=\"green\"></span>\n    </div>\n    <span class=\"red\"></span>\n    \"\"\"\n    tree = parser(html)\n    assert len(tree.select('div').css(\"span\").css(\".red\").matches) == 2\n\n\n@pytest.mark.parametrize(\"parser\", (HTMLParser,))\ndef test_css_chaining_two(parser):\n    html = \"\"\"\n    <script  integrity=\"sha512-DHpNaMnQ8GaECHElNcJkpGhIThksyXA==\" type=\"application/javascript\" class=\"weird_script\">\n        var counter = 10;\n    </script>\n    \"\"\"\n    tree = parser(html)\n    query = (\n        tree.select('script').text_contains('var counter = ').css(\".weird_script\")\n        .attribute_longer_than(\"integrity\", 25)\n    )\n    assert query\n\n\n@pytest.mark.parametrize(\"parser\", (HTMLParser, LexborHTMLParser))\ndef test_content_method(parser):\n    html = \"\"\"\n    <div>\n        <div id=\"main\">SuperTest</div>\n    </div>\n    \"\"\"\n    tree = parser(html)\n    assert tree.css_first('#main').child.text_content == \"SuperTest\"\n    assert tree.css_first('#main').text_content is None\n\n\n@pytest.mark.parametrize(\"parser\", (HTMLParser,))\ndef test_merge_text_nodes(parser):\n    html = \"\"\"<div><p><strong>J</strong>ohn</p><p>Doe</p></div>\"\"\"\n    tree = parser(html)\n    tree.unwrap_tags([\"strong\"])\n    node = tree.css_first(\"div\", strict=True)\n    node.merge_text_nodes()\n    assert node.html == \"<div><p>John</p><p>Doe</p></div>\"\n    text = tree.text(deep=True, separator=\" \", strip=True)\n    assert text == \"John Doe\"\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_css_first_first(parser):\n    html = '<h2 class=\"list-details__item__partial\" id=\"js-partial\">(1:1, 0:0, 0:0, 5:3)</h2>'\n    selector = \"h2.list-details__item__partial\"\n    find_first = parser(html).css_first(selector)\n    assert find_first.css_first(selector) is not None\n"
            }
        ]
    },
    {
        "conversations": [
            {
                "from": "human",
                "value": "Please learn from the content of this file."
            },
            {
                "from": "observation",
                "value": "# coding:utf-8\nfrom difflib import SequenceMatcher\n\nimport pytest\nfrom selectolax.parser import HTMLParser, Node\nfrom selectolax.lexbor import LexborHTMLParser, LexborNode\n\n\"\"\"\nWe'are testing only our own code.\nMany functionality are already tested in the Modest engine, so there is no reason to test every case.\n\"\"\"\n\n_PARSERS_PARAMETRIZER = (\"parser\", (HTMLParser, LexborHTMLParser),)\n\n\ndef test_encoding():\n    html = \"<div><p id=p1><p id=p2><p id=p3><a>link</a><p id=p4><p id=p5>text<p id=p6></div>\"\n    html = HTMLParser(html)\n    assert html.input_encoding == 'UTF-8'\n\n    html = b\"<div><p id=p1><p id=p2><p id=p3><a>link</a><p id=p4><p id=p5>text<p id=p6></div>\"\n    html = HTMLParser(html)\n    assert html.input_encoding == 'UTF-8'\n\n    html = \"<div>Привет мир!</div>\".encode('cp1251')\n    assert HTMLParser(html, detect_encoding=True).input_encoding == 'WINDOWS-1251'\n\n    html_utf = '<head><meta charset=\"WINDOWS-1251\"></head>'.encode('utf-8')\n    assert HTMLParser(html_utf, detect_encoding=True, use_meta_tags=True).input_encoding == 'WINDOWS-1251'\n\n    # UTF-16 not ASCII-readable\n    html_utf = '<head><meta charset=\"WINDOWS-1251\"></head>'.encode('utf-16le')\n    assert HTMLParser(html_utf, detect_encoding=True, use_meta_tags=True).input_encoding == 'UTF-16LE'\n\n    # Unencodable characters in string, should not throw an exception by default\n    html_unencodable = b'<div>Roboto+Condensed</div>'.decode('utf-7', errors='ignore')\n    assert HTMLParser(html_unencodable).input_encoding == 'UTF-8'\n\n    # decode_errrors='strict' should error out\n    try:\n        HTMLParser(html_unencodable, decode_errors='strict')\n        assert False\n    except Exception as e:\n        assert type(e) is UnicodeEncodeError\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_parser(parser):\n    html = parser(\"\")\n    assert isinstance(html, parser)\n\n    with pytest.raises(TypeError):\n        parser(123)\n\n    with pytest.raises(TypeError):\n        parser(\"asd\").css(123)\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_nodes(parser):\n    html = (\n        '<div><p id=\"p1\"></p><p id=\"p2\"></p><p id=\"p3\"><a>link</a></p>'\n        '<p id=\"p4\"></p><p id=\"p5\">text</p><p id=\"p6\"></p></div>'\n    )\n    htmlp = parser(html)\n\n    assert isinstance(htmlp.root, (Node, LexborNode))\n    assert isinstance(htmlp.body, (Node, LexborNode))\n    html_output = htmlp.html\n    assert len(html_output) >= len(html)\n    assert SequenceMatcher(None, html, html_output).ratio() > 0.8\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_root_css(parser):\n    tree = parser('test')\n    assert len(tree.root.css('data')) == 0\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_strip_tags_from_root(parser):\n    html = \"<body><div></div><script></script></body>\"\n    html_parser = parser(html)\n    html_parser.root.strip_tags(['div', 'script'])\n    assert html_parser.html == '<html><head></head><body></body></html>'\n\n    with pytest.raises(TypeError):\n        html_parser.strip_tags(1)\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_clone(parser):\n    html_parser = parser(\"\"\"<h1>Welcome</h1>\"\"\")\n    clone = html_parser.clone()\n    html_parser.root.css_first('h1').decompose()\n    del html_parser\n    assert clone.html == '<html><head></head><body><h1>Welcome</h1></body></html>'\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_tags(parser):\n    html_parser = parser(\"\"\"\n    <div><span><span></span></span></div>\n    <div><span></span></div>\n    <div><div></div></div>\n    <span></span>\n    <div></div>\n    \"\"\")\n    assert len(html_parser.tags('div')) == 5\n\n\n@pytest.mark.parametrize(*_PARSERS_PARAMETRIZER)\ndef test_preserves_doctype(parser):\n    html_parser = parser(\"\"\"\n    <!DOCTYPE html>\n    <html>\n        <head><title>Test</title></head>\n        <body><p>Hello World</p></body>\n    </html>\n    \"\"\")\n    assert '<!DOCTYPE html>' in html_parser.html\n"
            }
        ]
    },
    {
        "conversations": [
            {
                "from": "human",
                "value": "Please learn from the content of this file."
            },
            {
                "from": "observation",
                "value": "\"\"\"\nWe'are testing only our own code.\nMany functionality are already tested in the Modest engine, so there is no reason to test every case.\n\"\"\"\n\n# coding:utf-8\nfrom typing import Callable, NamedTuple, Sequence, Type, Union\n\nimport pytest\nfrom selectolax.parser import HTMLParser, Node, create_tag, parse_fragment\nfrom selectolax.lexbor import (\n    LexborHTMLParser,\n    LexborNode,\n    create_tag as lexbor_create_tag,\n    parse_fragment as lexbor_parse_fragment,\n)\n\n\nclass Impl(NamedTuple):\n    parser: Union[Type[HTMLParser], Type[LexborHTMLParser]]\n    node: Union[Type[Node], Type[LexborNode]]\n    tag_fn: Callable[[str], Union[Node, LexborNode]]\n    parse_fragment_fn: Callable[[str], Sequence[Union[Node, LexborNode]]]\n\n\n_IMPL_PARAMETRIZER = (\n    \"impl\",\n    (\n        Impl(\n            parser=HTMLParser,\n            node=Node,\n            tag_fn=create_tag,\n            parse_fragment_fn=parse_fragment,\n        ),\n        Impl(\n            parser=LexborHTMLParser,\n            node=LexborNode,\n            tag_fn=lexbor_create_tag,\n            parse_fragment_fn=lexbor_parse_fragment,\n        ),\n    )\n)\n\n\n@pytest.mark.parametrize(*_IMPL_PARAMETRIZER)\ndef test_create_tag(impl: Impl):\n    node = impl.tag_fn(\"p\")\n    assert isinstance(node, impl.node)\n    assert node.html == \"<p></p>\"\n\n\n@pytest.mark.parametrize(*_IMPL_PARAMETRIZER)\ndef test_create_header_tag(impl: Impl):\n    node = impl.tag_fn(\"header\")\n    assert isinstance(node, impl.node)\n    assert node.html == \"<header></header>\"\n\n# Cases to test parse_fragment():\n# - <doctyle> + <html> only\n# - HTML with <head>\n# - HTML with <body>\n# - HTML with <doctype>, <head> and <body>\n# - <head> and <body> only without <html>\n# - <head> only\n# - <body> only\n# - <link> and <meta>'s only (as content of <head>)\n# - <div>, <script> (as content of <body>)\n# - <link> and <div> next to each other (as invalid HTML, but valid fragment)\n\n\n@pytest.mark.parametrize(*_IMPL_PARAMETRIZER)\ndef test_parse_fragment_doctype_html(impl: Impl):\n    html = \"<!DOCTYPE html><html></html>\"\n    nodes = impl.parse_fragment_fn(html)\n    assert len(nodes) == 1\n    assert nodes[0].tag == \"html\"\n    assert nodes[0].html == \"<html></html>\"\n    assert nodes[0].parser.html == \"<!DOCTYPE html><html></html>\"\n\n    assert len(nodes[0].parser.css(\"head\")) == 0\n    assert len(nodes[0].parser.css(\"body\")) == 0\n\n\n@pytest.mark.parametrize(*_IMPL_PARAMETRIZER)\ndef test_parse_fragment_html_with_head(impl: Impl):\n    html = '<!DOCTYPE html><html><head><link href=\"http://\"></head></html>'\n    nodes = impl.parse_fragment_fn(html)\n    assert len(nodes) == 1\n    assert nodes[0].tag == \"html\"\n    assert nodes[0].html == '<html><head><link href=\"http://\"></head></html>'\n    assert nodes[0].parser.html == '<!DOCTYPE html><html><head><link href=\"http://\"></head></html>'\n\n    assert len(nodes[0].parser.css(\"head\")) == 1\n    assert len(nodes[0].parser.css(\"body\")) == 0\n\n\n@pytest.mark.parametrize(*_IMPL_PARAMETRIZER)\ndef test_parse_fragment_html_with_body(impl: Impl):\n    html = '<!DOCTYPE html><html><body><div><script src=\"http://\"></script></div></body></html>'\n    nodes = impl.parse_fragment_fn(html)\n    assert len(nodes) == 1\n    assert nodes[0].tag == \"html\"\n    assert nodes[0].html == '<html><body><div><script src=\"http://\"></script></div></body></html>'\n    assert nodes[0].parser.html == '<!DOCTYPE html><html><body><div><script src=\"http://\"></script></div></body></html>'\n\n    assert len(nodes[0].parser.css(\"head\")) == 0\n    assert len(nodes[0].parser.css(\"body\")) == 1\n\n\n@pytest.mark.parametrize(*_IMPL_PARAMETRIZER)\ndef test_parse_fragment_html_with_head_and_body(impl: Impl):\n    html = '<!DOCTYPE html><html><head><link href=\"http://\"></head><body><div><script src=\"http://\"></script></div></body></html>'  # noqa: E501\n    nodes = impl.parse_fragment_fn(html)\n    assert len(nodes) == 1\n    assert nodes[0].tag == \"html\"\n    assert nodes[0].html == '<html><head><link href=\"http://\"></head><body><div><script src=\"http://\"></script></div></body></html>'  # noqa: E501\n    assert nodes[0].parser.html == '<!DOCTYPE html><html><head><link href=\"http://\"></head><body><div><script src=\"http://\"></script></div></body></html>'  # noqa: E501\n\n    assert len(nodes[0].parser.css(\"head\")) == 1\n    assert len(nodes[0].parser.css(\"body\")) == 1\n\n\n@pytest.mark.parametrize(*_IMPL_PARAMETRIZER)\ndef test_parse_fragment_head_and_body_no_html(impl: Impl):\n    html = '<head><link href=\"http://\"></head><body><div><script src=\"http://\"></script></div></body>'\n    nodes = impl.parse_fragment_fn(html)\n    assert len(nodes) == 2\n    assert nodes[0].tag == \"head\"\n    assert nodes[1].tag == \"body\"\n    assert nodes[0].html == '<head><link href=\"http://\"></head>'\n    assert nodes[1].html == '<body><div><script src=\"http://\"></script></div></body>'\n    assert nodes[0].parser.html == '<html><head><link href=\"http://\"></head><body><div><script src=\"http://\"></script></div></body></html>'  # noqa: E501\n\n    assert len(nodes[0].parser.css(\"head\")) == 1\n    assert len(nodes[0].parser.css(\"body\")) == 1\n\n\n@pytest.mark.parametrize(*_IMPL_PARAMETRIZER)\ndef test_parse_fragment_head_no_html(impl: Impl):\n    html = '<head><link href=\"http://\"></head>'\n    nodes = impl.parse_fragment_fn(html)\n    assert len(nodes) == 1\n    assert nodes[0].tag == \"head\"\n    assert nodes[0].html == '<head><link href=\"http://\"></head>'\n    assert nodes[0].parser.html == '<html><head><link href=\"http://\"></head></html>'\n\n    assert len(nodes[0].parser.css(\"head\")) == 1\n    assert len(nodes[0].parser.css(\"body\")) == 0\n\n\n@pytest.mark.parametrize(*_IMPL_PARAMETRIZER)\ndef test_parse_fragment_body_no_html(impl: Impl):\n    html = '<body><div><script src=\"http://\"></script></div></body>'\n    nodes = impl.parse_fragment_fn(html)\n    assert len(nodes) == 1\n    assert nodes[0].tag == \"body\"\n    assert nodes[0].html == '<body><div><script src=\"http://\"></script></div></body>'\n    assert nodes[0].parser.html == '<html><body><div><script src=\"http://\"></script></div></body></html>'\n\n    assert len(nodes[0].parser.css(\"head\")) == 0\n    assert len(nodes[0].parser.css(\"body\")) == 1\n\n\n@pytest.mark.parametrize(*_IMPL_PARAMETRIZER)\ndef test_parse_fragment_fragment(impl: Impl):\n    html = '<link href=\"http://\"><div><script src=\"http://\"></script></div>'\n    nodes = impl.parse_fragment_fn(html)\n    assert len(nodes) == 2\n    assert nodes[0].tag == \"link\"\n    assert nodes[1].tag == \"div\"\n    assert nodes[0].html == '<link href=\"http://\">'\n    assert nodes[1].html == '<div><script src=\"http://\"></script></div>'\n\n    # NOTE: Ideally the full HTML would NOT contain `<html>`, `<head>` and `<body>` in this case,\n    # but this is technical limitation of the parser.\n    # But as long as user serializes fragment nodes by as `Node.html`, they should be fine.\n    assert nodes[0].parser.html == '<html><head><link href=\"http://\"></head><body><div><script src=\"http://\"></script></div></body></html>'  # noqa: E501\n    assert len(nodes[0].parser.css(\"head\")) == 1\n    assert len(nodes[0].parser.css(\"body\")) == 1\n"
            }
        ]
    },
    {
        "conversations": [
            {
                "from": "human",
                "value": "Please learn from the content of this file."
            },
            {
                "from": "observation",
                "value": "\nfrom selectolax.parser import HTMLParser, parse_fragment, create_tag\nhtml = \"\"\"\n<body>\n    <span id=\"vspan\"></span>\n    <h1>Welcome to selectolax tutorial</h1>\n    <div id=\"text\">\n        <p class='p3' style='display:none;'>Excepteur <i>sint</i> occaecat cupidatat non proident</p>\n        <p class='p3' vid>Lorem ipsum</p>\n    </div>\n    <div>\n        <p id='stext'>Lorem ipsum dolor sit amet, ea quo modus meliore platonem.</p>\n    </div>\n</body>\n\"\"\"\n\nfragment = \"\"\"\n<div>\n    <p class=\"p3\">\n        Hello there!\n    </p>\n</div>\n<script>\n    document.querySelector(\".p3\").addEventListener(\"click\", () => { ... });\n</script>\n\"\"\"\nParsing HTML\nThere are 3 ways to create or parse objects in Selectolax:\n\nParse HTML as a full document using HTMLParser()\nParse HTML as a fragment using parse_fragment()\nCreate single node using create_tag()\nHTMLParser() - This returns the HTML tree as parsed by Modest / Lexbor, unmodified. The HTML is assumed to be a full document. <html>, <head>, and <body> tags are added if missing.\n\nparse_fragment() - Intended for HTML fragments / partials. Returns a list of Nodes. Given HTML doesn't need to contain <html>, <head>, <body>. HTML can have multiple root elements.\n\ncreate_tag() - Create a single empty node for given tag.\n\nhtml_tree = HTMLParser(html)\nfrag_tree = parse_fragment(fragment)\nnode = create_tag(\"div\")\nSelect all p tags with class p3\nselector = \"p.p3\"\n\nfor node in HTMLParser(html).css(selector):\n    print('---------------------')\n    print('Node: %s' % node.html)\n    print('attributes: %s' % node.attributes)\n    print('node text: %s' % node.text(deep=True, separator='', strip=False))\n    print('tag: %s' % node.tag)\n    print('parent tag: %s' % node.parent.tag)\n    if node.last_child:\n        print('last child inside current node: %s' % node.last_child.html)\n    print('---------------------\\n')\n---------------------\nNode: <p class=\"p3\" style=\"display:none;\">Excepteur <i>sint</i> occaecat cupidatat non proident</p>\nattributes: {'class': 'p3', 'style': 'display:none;'}\nnode text: Excepteur sint occaecat cupidatat non proident\ntag: p\nparent tag: div\nlast child inside current node:  occaecat cupidatat non proident\n---------------------\n\n---------------------\nNode: <p class=\"p3\" vid=\"\">Lorem ipsum</p>\nattributes: {'class': 'p3', 'vid': None}\nnode text: Lorem ipsum\ntag: p\nparent tag: div\nlast child inside current node: Lorem ipsum\n---------------------\n\nSelect first match\nprint(\"H1: %s\" % HTMLParser(html).css_first('h1').text())\nH1: Welcome to selectolax tutorial\nDefault return value if there is no matches\nprint(\"Title: %s\" % HTMLParser(html).css_first('title', default='not-found'))\nTitle: not-found\nStrictly one match\nIf there multiple matches, you will get an error.\n\nHTMLParser(html).css_first(\"p.p3\", default='not-found', strict=True)\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n/var/folders/hz/kldp1y0d4tvd1x56cyg_b9mm0000gn/T/ipykernel_94350/4220316520.py in <module>\n----> 1 HTMLParser(html).css_first(\"p.p3\", default='not-found', strict=True)\n\n~/Projects/python/selectolax/selectolax/parser.pyx in selectolax.parser.HTMLParser.css_first()\n\n~/Projects/python/selectolax/selectolax/node.pxi in selectolax.parser.Node.css_first()\n\nValueError: Expected 1 match, but found 2 matches\nPrint parent of p#stext\nprint(HTMLParser(html).css_first('p#stext').parent.html)\n<div>\n        <p id=\"stext\">Lorem ipsum dolor sit amet, ea quo modus meliore platonem.</p>\n    </div>\nNested selectors\nHTMLParser(html).css_first('div#text').css_first('p:nth-child(2)').html\n'<p class=\"p3\" vid=\"\">Lorem ipsum</p>'\nIterate over all nodes on the current level\nfor node in HTMLParser(html).css(\"div#text\"):\n    for cnode in node.iter():\n        print(cnode.tag, cnode.html)\np <p class=\"p3\" style=\"display:none;\">Excepteur <i>sint</i> occaecat cupidatat non proident</p>\np <p class=\"p3\" vid=\"\">Lorem ipsum</p>\nTag removal\nhtml_parser = HTMLParser(html)\nfor node in html_parser.tags('p'):\n    node.decompose()\nprint(html_parser.body.html)\n<body>\n    <span id=\"vspan\"></span>\n    <h1>Welcome to selectolax tutorial</h1>\n    <div id=\"text\">\n        \n        \n    </div>\n    <div>\n        \n    </div>\n\n</body>\nTag unwrapping\nprint(html)\n<body>\n    <span id=\"vspan\"></span>\n    <h1>Welcome to selectolax tutorial</h1>\n    <div id=\"text\">\n        <p class='p3' style='display:none;'>Excepteur <i>sint</i> occaecat cupidatat non proident</p>\n        <p class='p3' vid>Lorem ipsum</p>\n    </div>\n    <div>\n        <p id='stext'>Lorem ipsum dolor sit amet, ea quo modus meliore platonem.</p>\n    </div>\n</body>\n\nhtml_parser = HTMLParser(html)\nhtml_parser.unwrap_tags(['p', 'i'])\nprint(html_parser.body.html)\n<body>\n    <span id=\"vspan\"></span>\n    <h1>Welcome to selectolax tutorial</h1>\n    <div id=\"text\">\n        Excepteur sint occaecat cupidatat non proident\n        Lorem ipsum\n    </div>\n    <div>\n        Lorem ipsum dolor sit amet, ea quo modus meliore platonem.\n    </div>\n\n</body>\nAttribute manipulation\nhtml_parser = HTMLParser(html)\nnode = html_parser.css_first('div#text')\nnode.attrs['data'] = 'secrect data'\nnode.attrs['id'] = 'new_id'\nprint(node.attributes)\ndel node.attrs['id']\nprint(node.attributes)\nprint(node.html)\n{'data': 'secrect data', 'id': 'new_id'}\n{'data': 'secrect data'}\n<div data=\"secrect data\">\n        <p class=\"p3\" style=\"display:none;\">Excepteur <i>sint</i> occaecat cupidatat non proident</p>\n        <p class=\"p3\" vid=\"\">Lorem ipsum</p>\n    </div>\nTree traversal\nhtml_parser = HTMLParser(html)\nfor node in html_parser.root.traverse():\n\n    if node.tag == '-text':\n        text = node.text(deep=True).strip()\n        if text:\n            print(text)\n    else:\n        print(node.tag)\nhtml\nhead\nbody\nspan\nh1\ndiv\np\ni\np\ndiv\np\nEncoding detection\nhtml = \"<div>Привет мир!</div>\"\n# Encoding detector works only with raw strings (bytes)\nhtml_bytes = html.encode('cp1251')\nhtml_bytes\nb'<div>\\xcf\\xf0\\xe8\\xe2\\xe5\\xf2 \\xec\\xe8\\xf0!</div>'\nHTMLParser(html_bytes, detect_encoding=True).input_encoding\n'WINDOWS-1251'\nEncoding detection using meta tags\nhtml = '<head><meta charset=\"WINDOWS-1251\"></head>'.encode('cp1251')\nHTMLParser(html, detect_encoding=True, use_meta_tags=True).input_encoding\n'WINDOWS-1251'\nhtml_utf = '<head><meta charset=\"WINDOWS-1251\"></head>'.encode('utf-8')\nHTMLParser(html_utf, detect_encoding=True, use_meta_tags=True).input_encoding\n'WINDOWS-1251'\nAdvanced selector\nAdvanced selector mimics some of the features of XPath that are missing in CSS.\n\nThe select methods accepts an optional initial CSS selector.\n\nhtml = \"\"\"\n<script>\n var super_variable = 100;\n</script>\n<script>\n console.log('debug');\n</script>\n\"\"\"\ntree = HTMLParser(html)\n\n[node.text() for node in tree.select('script').text_contains(\"super\").matches]\n['\\n var super_variable = 100;\\n']\nCSS chaining\nChaining allows executing multiple CSS selectors against the current scope quickly. Each new call filters previous results.\n\nhtml = \"\"\"\n<div id=\"container\">\n    <span class=\"red\"></span>\n    <span class=\"green\"></span>\n    <span class=\"red\"></span>\n    <span class=\"green\"></span>\n</div>\n\"\"\"\ntree = HTMLParser(html)\n\nprint([node.html for node in tree.select('div').css(\"span\").css(\".red\").matches])\n['<span class=\"red\"></span>', '<span class=\"red\"></span>']\nInserting nodes\nhtml = \"\"\"\n<div id=\"container\">\n    <span class=\"red\"></span>\n    <span class=\"green\"></span>\n    <span class=\"red\"></span>\n    <span class=\"green\"></span>\n</div>\n\"\"\"\ntree = HTMLParser(html)\n\n# Insert text\ndest_node = html_parser.css_first('.red')\ndest_node.insert_before(\"Hello\")\n\n# Insert nodes\nsubtree = HTMLParser(\"<div>Hi</div>\")\ndest_node = html_parser.css_first('.red')\ndest_node.insert_before(subtree)\n\n# Insert before, after, or append inside\nsubtree = HTMLParser(\"<div>Car</div>\")\ndest_node = html_parser.css_first('.green')\ndest_node.insert_before(subtree)\ndest_node.insert_after(subtree)\ndest_node.insert_child(subtree)"
            }
        ]
    }
]